{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basketball Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "234nbi9YdFGq",
        "xhWhFly8dpo6",
        "HeqE4yyUd_04",
        "SEBAfvGui3Gy",
        "6ftFUWvejLpg",
        "qrMnpUAfc2R4",
        "thNF2Bp2jeZ0",
        "q2eK77LZj_-v",
        "m2en1HF3k30Y",
        "bM5j7H_PRpI5",
        "NgwyAf0fmEZT",
        "vDpOIUPwzsGD",
        "XlvBq4Gq16bV",
        "bDekSr_TzLhy"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mvanbergen/EnginePreheater/blob/master/Basketball_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFuQ-JxAG2Ta",
        "colab_type": "text"
      },
      "source": [
        "## Install Pre-reqs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpXzG9JObomV",
        "colab_type": "code",
        "outputId": "5e0b6dcf-ae47-463d-b109-e858f621e7c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!python --version"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Transport endpoint is not connected\n",
            "Python 3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVTEDGCPmJ5c",
        "colab_type": "text"
      },
      "source": [
        "Install moviepy required for writing audio file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asHaPFT1mI1-",
        "colab_type": "code",
        "outputId": "739f154c-630b-4d06-9301-f2de15efb241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!pip install moviepy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.6/dist-packages (0.2.3.5)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from moviepy) (2.4.1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.6/dist-packages (from moviepy) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from moviepy) (1.18.4)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.6/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio<3.0,>=2.1.2->moviepy) (7.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeeW5XBGFgf9",
        "colab_type": "code",
        "outputId": "2cddabcd-16a2-4508-9b0e-cf2004149ee5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "!pip show numpy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: numpy\n",
            "Version: 1.17.3\n",
            "Summary: NumPy is the fundamental package for array computing with Python.\n",
            "Home-page: https://www.numpy.org\n",
            "Author: Travis E. Oliphant et al.\n",
            "Author-email: None\n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: \n",
            "Required-by: yellowbrick, xgboost, xarray, wordcloud, umap-learn, torchvision, torchtext, torch, tifffile, thinc, Theano, tensorflow, tensorflow-probability, tensorflow-hub, tensorflow-gpu, tensorflow-datasets, tensorboard, tables, statsmodels, spacy, sklearn-pandas, seaborn, scs, scipy, scikit-learn, resampy, PyWavelets, python-louvain, pystan, pysndfile, pymc3, pyemd, pyarrow, plotnine, patsy, pandas, osqp, opt-einsum, opencv-python, opencv-contrib-python, numexpr, numba, np-utils, nibabel, moviepy, mlxtend, mizani, missingno, matplotlib, matplotlib-venn, lucid, lightgbm, librosa, knnimpute, Keras, Keras-Preprocessing, Keras-Applications, kapre, jpeg4py, jaxlib, jax, imgaug, imbalanced-learn, imageio, imagecodecs, hyperopt, h5py, gym, gensim, folium, fix-yahoo-finance, featuretools, fbprophet, fastdtw, fastai, fancyimpute, fa2, ecos, daft, cvxpy, cufflinks, cmdstanpy, chainer, Bottleneck, bokeh, blis, autograd, atari-py, astropy, altair, albumentations\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqEorHFCUAmH",
        "colab_type": "code",
        "outputId": "20de2935-f406-44a4-bdc0-8b844612c3d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "!pip install numpy==1.17.3"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.17.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/46/ae6773894f7eacf53308086287897ec568eac9768918d913d5b9d366c5db/numpy-1.17.3-cp36-cp36m-manylinux1_x86_64.whl (20.0MB)\n",
            "\u001b[K     |████████████████████████████████| 20.0MB 1.4MB/s \n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.18.4\n",
            "    Uninstalling numpy-1.18.4:\n",
            "      Successfully uninstalled numpy-1.18.4\n",
            "Successfully installed numpy-1.17.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b27wvilt9o9x",
        "colab_type": "text"
      },
      "source": [
        "Install Proper Version of Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pANui06N9igU",
        "colab_type": "code",
        "outputId": "b9fb89d6-9689-4ab5-aac6-fa70adcf73b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "!pip show tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.2.0rc4\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: grpcio, h5py, six, protobuf, wheel, gast, numpy, scipy, astunparse, absl-py, opt-einsum, tensorboard, termcolor, google-pasta, tensorflow-estimator, keras-preprocessing, wrapt\n",
            "Required-by: fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n5iLKNM9tHZ",
        "colab_type": "code",
        "outputId": "3d1c4ec0-ea46-451b-ef01-8179c1912f43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        }
      },
      "source": [
        "!pip install tensorflow-gpu==1.15.2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.15.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/ca/58e40e5077fa2a92004f398d705a288e958434f123938f4ce75ffe25b64b/tensorflow_gpu-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (411.0MB)\n",
            "\u001b[K     |████████████████████████████████| 411.0MB 32kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.12.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (3.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.28.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 46.3MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 39.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.0.8)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.34.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.17.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (3.2.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.15.2) (46.3.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.2.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.2) (2.10.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=03274fd1c3520a058142af3db713e15a678757e29aca8d23a46593eede0e58f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorflow-estimator<2.3.0,>=2.2.0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0rc0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, gast, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.2.1\n",
            "    Uninstalling tensorboard-2.2.1:\n",
            "      Successfully uninstalled tensorboard-2.2.1\n",
            "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txE9mLITtKon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_Ui1DdAPcaq",
        "colab_type": "text"
      },
      "source": [
        "Install ffmpeg Python Wrapper Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xb-tTeIPblX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install ffmpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwStM7ajb4gH",
        "colab_type": "text"
      },
      "source": [
        "##Check GPU configured"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkrZcAhwcb-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "  random_image_gpu = tf.random_normal((100, 100, 100, 3))\n",
        "  net_gpu = tf.layers.conv2d(random_image_gpu, 32, 7)\n",
        "  net_gpu = tf.reduce_sum(net_gpu)\n",
        "  \n",
        "sess = tf.Session(config=config)\n",
        "\n",
        "try:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  print('ok')\n",
        "except tf.errors.InvalidArgumentError:\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhSbKkWrUtZo",
        "colab_type": "text"
      },
      "source": [
        "##Map Google Drive\n",
        "Need to map the google drive folder for access to models and input video as well as writing the output video."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrjDbw_1Usa5",
        "colab_type": "code",
        "outputId": "98f79d55-8e8e-4e1a-cd1d-33da91ce8f9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from os.path import join\n",
        "from google.colab import drive\n",
        "\n",
        "ROOT = \"/content/drive\"\n",
        "drive.mount(ROOT, force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlbKisqCr1vq",
        "colab_type": "code",
        "outputId": "877934ea-6e2b-4a7a-eb82-8401bc95514f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "PROJ = \"My Drive/OBJ_Detect_POC\" # This is a custom path.\n",
        "PROJECT_PATH = join(ROOT, PROJ)\n",
        "\n",
        "%cd $PROJECT_PATH"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/OBJ_Detect_POC\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "234nbi9YdFGq",
        "colab_type": "text"
      },
      "source": [
        "##Git cloneing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfsTatJ4dDo7",
        "colab_type": "code",
        "outputId": "dde4c3d0-dec4-496c-e892-ac1613a677bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# !git clone https://github.com/dodandeniya/panda-model.git\n",
        "%cd learning/\n",
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/OBJ_Detect_POC/learning\n",
            "fatal: destination path 'models' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhWhFly8dpo6",
        "colab_type": "text"
      },
      "source": [
        "##Creating blank images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm3XFTYodq_x",
        "colab_type": "code",
        "outputId": "d4097dcb-23af-4111-a741-973ce8048e29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%cd annotations\n",
        "\n",
        "!mkdir trimaps\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "image = Image.new('RGB', (300, 300))\n",
        "\n",
        "for filename in os.listdir('xmls'):\n",
        "  filename = os.path.splitext(filename)[0]\n",
        "  image.save('trimaps/' + filename + '.png')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/OBJ_Detect_POC/learning/annotations\n",
            "mkdir: cannot create directory ‘trimaps’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeqE4yyUd_04",
        "colab_type": "text"
      },
      "source": [
        "##Compile object_detection API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kcbJr4LeA3H",
        "colab_type": "code",
        "outputId": "f12ea36a-1b18-45af-8045-c3cbfab909fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "%cd ~\n",
        "%cd /content\n",
        "%cd $PROJECT_PATH/learning/models/research\n",
        "!pwd\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n",
            "/content\n",
            "/content/drive/My Drive/OBJ_Detect_POC/learning/models/research\n",
            "/content/drive/My Drive/OBJ_Detect_POC/learning/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55piJ18_ildy",
        "colab_type": "text"
      },
      "source": [
        "## Adding system variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Hd32Y8Zipwd",
        "colab_type": "code",
        "outputId": "ddd921f2-a2dd-4720-b28f-d14e98aa833c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "%cd ~\n",
        "%cd /content\n",
        "%cd $PROJECT_PATH/learning/\n",
        "import os\n",
        "os.environ['PYTHONPATH'] = '/env/python'\n",
        "os.environ['PYTHONPATH'] += ':/content/drive/My Drive/OBJ_Detect_POC/learning/models/research/:/content/drive/My Drive/OBJ_Detect_POC/learning/models/research/slim/'\n",
        "os.environ['PYTHONPATH'] += ':/content/drive/My Drive/OBJ_Detect_POC/learning/models/research/:/content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/'\n",
        "print(os.environ['PYTHONPATH'])\n",
        "#!python /content/drive/My\\ Drive/OBJ_Detect_POC/learning/models/research/object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n",
            "/content\n",
            "/content/drive/My Drive/OBJ_Detect_POC/learning\n",
            "/env/python:/content/drive/My Drive/OBJ_Detect_POC/learning/models/research/:/content/drive/My Drive/OBJ_Detect_POC/learning/models/research/slim/:/content/drive/My Drive/OBJ_Detect_POC/learning/models/research/:/content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUuhskRNSl_z",
        "colab_type": "code",
        "outputId": "46cb4348-70c3-4253-b1c7-8fed9d80cc63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/OBJ_Detect_POC/learning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEBAfvGui3Gy",
        "colab_type": "text"
      },
      "source": [
        "##Generate training and validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIvHYBKrjGL_",
        "colab_type": "code",
        "outputId": "7843b342-2231-4a52-a7fd-2a1b460f4ca1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "!python create_tf_record.py \\\n",
        "    --data_dir=!pwd \\\n",
        "    --output_dir=!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From create_tf_record.py:178: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0322 15:35:14.980551 140311107442560 module_wrapper.py:139] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "I0322 15:35:14.982436 140311107442560 create_tf_record.py:153] Reading from train dataset.\n",
            "I0322 15:35:15.703924 140311107442560 create_tf_record.py:168] 71 training and 31 validation examples.\n",
            "WARNING:tensorflow:From create_tf_record.py:131: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0322 15:35:15.704535 140311107442560 module_wrapper.py:139] From create_tf_record.py:131: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "I0322 15:35:15.712748 140311107442560 create_tf_record.py:134] On image 0 of 71\n",
            "/content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/utils/dataset_util.py:79: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
            "  if not xml:\n",
            "I0322 15:35:17.038079 140311107442560 create_tf_record.py:134] On image 0 of 31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ftFUWvejLpg",
        "colab_type": "text"
      },
      "source": [
        "##Download and unzip pre-trained model - SSD_MOBILENET_V1_COCO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piIvu4L3jbpa",
        "colab_type": "code",
        "outputId": "e04f8bab-d325-49d6-e7b0-34471404a274",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "\n",
        "MODEL = 'ssd_mobilenet_v1_coco_2018_01_28'\n",
        "# MODEL = 'mask_rcnn_inception_v2_coco_2018_01_28'\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = 'pretrained_model'\n",
        "\n",
        "!mkdir \"pretrained_model\"\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "  opener = urllib.request.URLopener()\n",
        "  opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "  shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘pretrained_model’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrMnpUAfc2R4",
        "colab_type": "text"
      },
      "source": [
        "## Download and unzipo pre-trained model - faster_rcnn_inception_v2_coco"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fgn0dqqJdek5",
        "colab_type": "code",
        "outputId": "e89f91c4-d116-4884-b4c0-61ebab5eb016",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "%cd ~\n",
        "%cd /content\n",
        "%cd $PROJECT_PATH/learning/\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "\n",
        "MODEL = 'faster_rcnn_inception_v2_coco_2018_01_28'\n",
        "# MODEL = 'mask_rcnn_inception_v2_coco_2018_01_28'\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = 'pretrained_model_rcnn'\n",
        "\n",
        "!mkdir \"pretrained_model_rcnn\"\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "  opener = urllib.request.URLopener()\n",
        "  opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "  shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n",
            "/content\n",
            "/content/drive/My Drive/OBJ_Detect_POC/learning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thNF2Bp2jeZ0",
        "colab_type": "text"
      },
      "source": [
        "##Modify pipline.config file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGjuUXDijv39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "filename = '/content/drive/My Drive/OBJ_Detect_POC/learning/pretrained_model/pipeline.config'\n",
        "with open(filename) as f:\n",
        "  s = f.read()\n",
        "with open(filename, 'w') as f:\n",
        "  s = re.sub('PATH_TO_BE_CONFIGURED/model.ckpt', '/content/drive/My Drive/OBJ_Detect_POC/learning/pretrained_model/model.ckpt', s)\n",
        "  s = re.sub('PATH_TO_BE_CONFIGURED/mscoco_train.record', '/content/drive/My Drive/OBJ_Detect_POC/learning/train.record', s)\n",
        "  s = re.sub('PATH_TO_BE_CONFIGURED/mscoco_val.record', '/content/drive/My Drive/OBJ_Detect_POC/learning/val.record', s)\n",
        "  s = re.sub('PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt', '/content/drive/My Drive/OBJ_Detect_POC/learning/annotations/label_map.pbtxt', s)\n",
        "  f.write(s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVLIyXMxSpO6",
        "colab_type": "text"
      },
      "source": [
        "Utility to Count Images in the Folders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSaCUkXGSoVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "test_path = \"/content/drive/My Drive/OBJ_Detect_POC/learning/images\"\n",
        "len_dir = len(os.listdir(test_path))\n",
        "print(\"{} files inside the {}\".format(len_dir, test_path))\n",
        "\n",
        "test_path = \"/content/drive/My Drive/OBJ_Detect_POC/learning/test/\"\n",
        "len_dir = len(os.listdir(test_path))\n",
        "print(\"{} files inside the {}\".format(len_dir, test_path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2eK77LZj_-v",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "##Train new model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1vgKcfHkRhF",
        "colab_type": "code",
        "outputId": "53710cd8-c724-4f5e-de0f-7f4f49b17427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd ~\n",
        "%cd /content\n",
        "%cd drive/My Drive/OBJ_Detect_POC/learning/\n",
        "!python models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path=\"/content/drive/My Drive/OBJ_Detect_POC/learning/pipeline.config\" \\\n",
        "    --model_dir=\"/content/drive/My Drive/OBJ_Detect_POC/learning/trained\" \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps=20000"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n",
            "/content\n",
            "/content/drive/My Drive/OBJ_Detect_POC/learning\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From models/research/object_detection/model_main.py:109: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0328 16:34:46.781351 140610591364992 module_wrapper.py:139] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/model_lib.py:628: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "W0328 16:34:47.164327 140610591364992 module_wrapper.py:139] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/model_lib.py:628: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0328 16:34:47.164523 140610591364992 model_lib.py:629] Forced number of epochs for all eval validations to be 1.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0328 16:34:47.164636 140610591364992 module_wrapper.py:139] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/utils/config_util.py:488: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 20000\n",
            "I0328 16:34:47.164705 140610591364992 config_util.py:488] Maybe overwriting train_steps: 20000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0328 16:34:47.164767 140610591364992 config_util.py:488] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0328 16:34:47.164819 140610591364992 config_util.py:488] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0328 16:34:47.164871 140610591364992 config_util.py:488] Maybe overwriting eval_num_epochs: 1\n",
            "INFO:tensorflow:Maybe overwriting load_pretrained: True\n",
            "I0328 16:34:47.164919 140610591364992 config_util.py:488] Maybe overwriting load_pretrained: True\n",
            "INFO:tensorflow:Ignoring config override key: load_pretrained\n",
            "I0328 16:34:47.164965 140610591364992 config_util.py:498] Ignoring config override key: load_pretrained\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0328 16:34:47.165725 140610591364992 model_lib.py:645] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "I0328 16:34:47.165812 140610591364992 model_lib.py:680] create_estimator_and_inputs: use_tpu False, export_to_tpu False\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/content/drive/My Drive/OBJ_Detect_POC/learning/trained', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe1fc1a1f28>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0328 16:34:47.166268 140610591364992 estimator.py:212] Using config: {'_model_dir': '/content/drive/My Drive/OBJ_Detect_POC/learning/trained', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe1fc1a1f28>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fe1fc1bb510>) includes params argument, but params are not passed to Estimator.\n",
            "W0328 16:34:47.166493 140610591364992 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fe1fc1bb510>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0328 16:34:47.167335 140610591364992 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0328 16:34:47.167491 140610591364992 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0328 16:34:47.167688 140610591364992 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0328 16:34:48.785209 140610591364992 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0328 16:34:48.795743 140610591364992 module_wrapper.py:139] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
            "\n",
            "W0328 16:34:48.795964 140610591364992 module_wrapper.py:139] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0328 16:34:49.241530 140610591364992 module_wrapper.py:139] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0328 16:34:49.243279 140610591364992 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W0328 16:34:49.249770 140610591364992 deprecation.py:323] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0328 16:34:49.250309 140610591364992 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0328 16:34:49.271278 140610591364992 deprecation.py:323] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.\n",
            "\n",
            "W0328 16:34:51.610320 140610591364992 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
            "\n",
            "W0328 16:34:59.900418 140610591364992 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0328 16:34:59.971688 140610591364992 deprecation.py:323] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0328 16:35:02.268569 140610591364992 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0328 16:35:06.094587 140610591364992 api.py:332] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W0328 16:35:10.190284 140610591364992 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "W0328 16:35:10.191310 140610591364992 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/inputs.py:166: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0328 16:35:11.112947 140610591364992 deprecation.py:323] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/inputs.py:166: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\n",
            "\n",
            "W0328 16:35:14.246693 140610591364992 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "W0328 16:35:14.797566 140610591364992 deprecation.py:323] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/builders/dataset_builder.py:158: batch_and_drop_remainder (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.batch(..., drop_remainder=True)`.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0328 16:35:14.809363 140610591364992 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/meta_architectures/ssd_meta_arch.py:589: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "W0328 16:35:15.111916 140610591364992 module_wrapper.py:139] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/meta_architectures/ssd_meta_arch.py:589: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0328 16:35:15.112315 140610591364992 module_wrapper.py:139] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0328 16:35:15.114373 140610591364992 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "W0328 16:35:16.677837 140610591364992 module_wrapper.py:139] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 16:35:16.687335 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 16:35:16.716555 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 16:35:16.744213 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 16:35:16.772054 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 16:35:16.799213 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 16:35:16.828262 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "W0328 16:35:16.860336 140610591364992 module_wrapper.py:139] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
            "\n",
            "W0328 16:35:16.861007 140610591364992 module_wrapper.py:139] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/model_lib.py:353: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "W0328 16:35:17.654360 140610591364992 module_wrapper.py:139] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/model_lib.py:353: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0328 16:35:18.251261 140610591364992 module_wrapper.py:139] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1163: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W0328 16:35:22.015071 140610591364992 module_wrapper.py:139] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1163: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
            "\n",
            "W0328 16:35:22.020066 140610591364992 module_wrapper.py:139] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
            "\n",
            "W0328 16:35:22.021142 140610591364992 module_wrapper.py:139] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1275: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "W0328 16:35:22.530127 140610591364992 module_wrapper.py:139] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/meta_architectures/ssd_meta_arch.py:1275: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/model_lib.py:380: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0328 16:35:22.532372 140610591364992 module_wrapper.py:139] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/model_lib.py:380: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/utils/learning_schedules.py:66: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "W0328 16:35:22.532655 140610591364992 module_wrapper.py:139] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/utils/learning_schedules.py:66: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/builders/optimizer_builder.py:47: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
            "\n",
            "W0328 16:35:22.540628 140610591364992 module_wrapper.py:139] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/builders/optimizer_builder.py:47: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/model_lib.py:398: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "W0328 16:35:22.540866 140610591364992 module_wrapper.py:139] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/model_lib.py:398: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0328 16:35:24.243989 140610591364992 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/model_lib.py:515: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0328 16:35:27.323630 140610591364992 module_wrapper.py:139] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/model_lib.py:515: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/model_lib.py:519: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "W0328 16:35:27.879982 140610591364992 module_wrapper.py:139] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/model_lib.py:519: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/model_lib.py:520: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
            "\n",
            "W0328 16:35:27.880241 140610591364992 module_wrapper.py:139] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/model_lib.py:520: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0328 16:35:27.880578 140610591364992 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0328 16:35:27.881685 140610591364992 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0328 16:35:31.472653 140610591364992 monitored_session.py:240] Graph was finalized.\n",
            "2020-03-28 16:35:31.473053: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-03-28 16:35:31.478635: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-03-28 16:35:31.478819: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1d4d100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-03-28 16:35:31.478847: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-03-28 16:35:31.481531: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-03-28 16:35:31.568018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 16:35:31.568670: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1d4d640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-03-28 16:35:31.568697: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-03-28 16:35:31.568865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 16:35:31.569355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-03-28 16:35:31.569650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-03-28 16:35:31.570758: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-03-28 16:35:31.571875: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-03-28 16:35:31.572251: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-03-28 16:35:31.573605: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-03-28 16:35:31.574623: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-03-28 16:35:31.577592: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-03-28 16:35:31.577740: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 16:35:31.578344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 16:35:31.578810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-03-28 16:35:31.578864: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-03-28 16:35:31.580044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-03-28 16:35:31.580087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-03-28 16:35:31.580098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-03-28 16:35:31.580208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 16:35:31.580767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 16:35:31.581340: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-03-28 16:35:31.581375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14889 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-13759\n",
            "I0328 16:35:31.585384 140610591364992 saver.py:1284] Restoring parameters from /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-13759\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "W0328 16:35:34.647195 140610591364992 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0328 16:35:35.378718 140610591364992 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0328 16:35:35.672126 140610591364992 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 13759 into /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt.\n",
            "I0328 16:35:44.102061 140610591364992 basic_session_run_hooks.py:606] Saving checkpoints for 13759 into /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt.\n",
            "2020-03-28 16:35:55.920621: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-03-28 16:36:00.791019: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "INFO:tensorflow:loss = 1.4782035, step = 13759\n",
            "I0328 16:36:03.150118 140610591364992 basic_session_run_hooks.py:262] loss = 1.4782035, step = 13759\n",
            "INFO:tensorflow:global_step/sec: 1.29732\n",
            "I0328 16:37:20.231494 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.29732\n",
            "INFO:tensorflow:loss = 1.2938619, step = 13859 (77.083 sec)\n",
            "I0328 16:37:20.232744 140610591364992 basic_session_run_hooks.py:260] loss = 1.2938619, step = 13859 (77.083 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.3693\n",
            "I0328 16:38:33.261319 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.3693\n",
            "INFO:tensorflow:loss = 1.1527016, step = 13959 (73.031 sec)\n",
            "I0328 16:38:33.263417 140610591364992 basic_session_run_hooks.py:260] loss = 1.1527016, step = 13959 (73.031 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.35543\n",
            "I0328 16:39:47.038805 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.35543\n",
            "INFO:tensorflow:loss = 1.645068, step = 14059 (73.777 sec)\n",
            "I0328 16:39:47.039983 140610591364992 basic_session_run_hooks.py:260] loss = 1.645068, step = 14059 (73.777 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.32355\n",
            "I0328 16:41:02.593287 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.32355\n",
            "INFO:tensorflow:loss = 1.9713514, step = 14159 (78.071 sec)\n",
            "I0328 16:41:05.111300 140610591364992 basic_session_run_hooks.py:260] loss = 1.9713514, step = 14159 (78.071 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.22432\n",
            "I0328 16:42:24.271486 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.22432\n",
            "INFO:tensorflow:loss = 2.2739332, step = 14259 (79.161 sec)\n",
            "I0328 16:42:24.272611 140610591364992 basic_session_run_hooks.py:260] loss = 2.2739332, step = 14259 (79.161 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.46278\n",
            "I0328 16:43:32.634516 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.46278\n",
            "INFO:tensorflow:loss = 1.4912553, step = 14359 (68.363 sec)\n",
            "I0328 16:43:32.635827 140610591364992 basic_session_run_hooks.py:260] loss = 1.4912553, step = 14359 (68.363 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.49241\n",
            "I0328 16:44:39.640392 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.49241\n",
            "INFO:tensorflow:loss = 1.2649586, step = 14459 (67.006 sec)\n",
            "I0328 16:44:39.641587 140610591364992 basic_session_run_hooks.py:260] loss = 1.2649586, step = 14459 (67.006 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 14560 into /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt.\n",
            "I0328 16:45:46.296921 140610591364992 basic_session_run_hooks.py:606] Saving checkpoints for 14560 into /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W0328 16:45:46.500872 140610591364992 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0328 16:45:48.479391 140610591364992 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 16:45:50.101822 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 16:45:50.130917 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 16:45:50.159398 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 16:45:50.193861 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 16:45:50.224349 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 16:45:50.252115 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/eval_util.py:796: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0328 16:45:50.997370 140610591364992 deprecation.py:323] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/eval_util.py:796: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/utils/visualization_utils.py:498: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0328 16:45:51.191331 140610591364992 deprecation.py:323] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/utils/visualization_utils.py:498: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/utils/visualization_utils.py:1044: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
            "\n",
            "W0328 16:45:51.351868 140610591364992 module_wrapper.py:139] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/utils/visualization_utils.py:1044: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/model_lib.py:484: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "W0328 16:45:51.436284 140610591364992 module_wrapper.py:139] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/model_lib.py:484: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0328 16:45:51.635679 140610591364992 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-03-28T16:45:51Z\n",
            "I0328 16:45:51.651413 140610591364992 evaluation.py:255] Starting evaluation at 2020-03-28T16:45:51Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0328 16:45:51.915495 140610591364992 monitored_session.py:240] Graph was finalized.\n",
            "2020-03-28 16:45:51.916599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 16:45:51.917024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-03-28 16:45:51.917149: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-03-28 16:45:51.917185: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-03-28 16:45:51.917210: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-03-28 16:45:51.917243: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-03-28 16:45:51.917265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-03-28 16:45:51.917286: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-03-28 16:45:51.917310: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-03-28 16:45:51.917391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 16:45:51.917851: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 16:45:51.918237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-03-28 16:45:51.918287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-03-28 16:45:51.918302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-03-28 16:45:51.918312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-03-28 16:45:51.918404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 16:45:51.918819: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 16:45:51.919188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14889 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-14560\n",
            "I0328 16:45:51.921163 140610591364992 saver.py:1284] Restoring parameters from /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-14560\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0328 16:45:52.554961 140610591364992 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0328 16:45:52.657788 140610591364992 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 31 images.\n",
            "I0328 16:45:59.267543 140608136017664 coco_evaluation.py:205] Performing evaluation on 31 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0328 16:45:59.268276 140608136017664 coco_tools.py:115] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0328 16:45:59.271686 140608136017664 coco_tools.py:137] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.27s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.07s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.670\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.296\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.050\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.209\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.462\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.370\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.413\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.413\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.094\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.265\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.502\n",
            "INFO:tensorflow:Finished evaluation at 2020-03-28-16:46:01\n",
            "I0328 16:46:01.168120 140610591364992 evaluation.py:275] Finished evaluation at 2020-03-28-16:46:01\n",
            "INFO:tensorflow:Saving dict for global step 14560: DetectionBoxes_Precision/mAP = 0.34181657, DetectionBoxes_Precision/mAP (large) = 0.4624529, DetectionBoxes_Precision/mAP (medium) = 0.20884912, DetectionBoxes_Precision/mAP (small) = 0.049834985, DetectionBoxes_Precision/mAP@.50IOU = 0.6698545, DetectionBoxes_Precision/mAP@.75IOU = 0.29605943, DetectionBoxes_Recall/AR@1 = 0.3695861, DetectionBoxes_Recall/AR@10 = 0.41321594, DetectionBoxes_Recall/AR@100 = 0.41321594, DetectionBoxes_Recall/AR@100 (large) = 0.5024845, DetectionBoxes_Recall/AR@100 (medium) = 0.2654882, DetectionBoxes_Recall/AR@100 (small) = 0.09375, Loss/classification_loss = 3.7325122, Loss/localization_loss = 1.9771343, Loss/regularization_loss = 0.3467115, Loss/total_loss = 6.056358, global_step = 14560, learning_rate = 0.004, loss = 6.056358\n",
            "I0328 16:46:01.168423 140610591364992 estimator.py:2049] Saving dict for global step 14560: DetectionBoxes_Precision/mAP = 0.34181657, DetectionBoxes_Precision/mAP (large) = 0.4624529, DetectionBoxes_Precision/mAP (medium) = 0.20884912, DetectionBoxes_Precision/mAP (small) = 0.049834985, DetectionBoxes_Precision/mAP@.50IOU = 0.6698545, DetectionBoxes_Precision/mAP@.75IOU = 0.29605943, DetectionBoxes_Recall/AR@1 = 0.3695861, DetectionBoxes_Recall/AR@10 = 0.41321594, DetectionBoxes_Recall/AR@100 = 0.41321594, DetectionBoxes_Recall/AR@100 (large) = 0.5024845, DetectionBoxes_Recall/AR@100 (medium) = 0.2654882, DetectionBoxes_Recall/AR@100 (small) = 0.09375, Loss/classification_loss = 3.7325122, Loss/localization_loss = 1.9771343, Loss/regularization_loss = 0.3467115, Loss/total_loss = 6.056358, global_step = 14560, learning_rate = 0.004, loss = 6.056358\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 14560: /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-14560\n",
            "I0328 16:46:01.827217 140610591364992 estimator.py:2109] Saving 'checkpoint_path' summary for global step 14560: /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-14560\n",
            "INFO:tensorflow:global_step/sec: 1.21671\n",
            "I0328 16:46:01.829357 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.21671\n",
            "INFO:tensorflow:loss = 1.3823844, step = 14559 (82.189 sec)\n",
            "I0328 16:46:01.830400 140610591364992 basic_session_run_hooks.py:260] loss = 1.3823844, step = 14559 (82.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.4565\n",
            "I0328 16:47:10.486930 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.4565\n",
            "INFO:tensorflow:loss = 1.1519989, step = 14659 (68.658 sec)\n",
            "I0328 16:47:10.488034 140610591364992 basic_session_run_hooks.py:260] loss = 1.1519989, step = 14659 (68.658 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.45662\n",
            "I0328 16:48:19.138845 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.45662\n",
            "INFO:tensorflow:loss = 1.1348374, step = 14759 (68.652 sec)\n",
            "I0328 16:48:19.140466 140610591364992 basic_session_run_hooks.py:260] loss = 1.1348374, step = 14759 (68.652 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.4516\n",
            "I0328 16:49:28.028142 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.4516\n",
            "INFO:tensorflow:loss = 1.873291, step = 14859 (68.889 sec)\n",
            "I0328 16:49:28.029402 140610591364992 basic_session_run_hooks.py:260] loss = 1.873291, step = 14859 (68.889 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.44802\n",
            "I0328 16:50:37.087957 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.44802\n",
            "INFO:tensorflow:loss = 1.5873892, step = 14959 (69.060 sec)\n",
            "I0328 16:50:37.089466 140610591364992 basic_session_run_hooks.py:260] loss = 1.5873892, step = 14959 (69.060 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.46477\n",
            "I0328 16:51:45.357991 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.46477\n",
            "INFO:tensorflow:loss = 1.8695251, step = 15059 (68.270 sec)\n",
            "I0328 16:51:45.358986 140610591364992 basic_session_run_hooks.py:260] loss = 1.8695251, step = 15059 (68.270 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.47577\n",
            "I0328 16:52:53.119005 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.47577\n",
            "INFO:tensorflow:loss = 1.386837, step = 15159 (67.762 sec)\n",
            "I0328 16:52:53.120589 140610591364992 basic_session_run_hooks.py:260] loss = 1.386837, step = 15159 (67.762 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.47613\n",
            "I0328 16:54:00.863884 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.47613\n",
            "INFO:tensorflow:loss = 1.5130255, step = 15259 (67.744 sec)\n",
            "I0328 16:54:00.864862 140610591364992 basic_session_run_hooks.py:260] loss = 1.5130255, step = 15259 (67.744 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.46859\n",
            "I0328 16:55:08.956439 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.46859\n",
            "INFO:tensorflow:loss = 1.5081986, step = 15359 (68.093 sec)\n",
            "I0328 16:55:08.957921 140610591364992 basic_session_run_hooks.py:260] loss = 1.5081986, step = 15359 (68.093 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 15416 into /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt.\n",
            "I0328 16:55:46.487447 140610591364992 basic_session_run_hooks.py:606] Saving checkpoints for 15416 into /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0328 16:55:48.596439 140610591364992 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 16:55:49.982523 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 16:55:50.012228 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 16:55:50.041097 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 16:55:50.070423 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 16:55:50.100071 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 16:55:50.134708 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0328 16:55:51.491529 140610591364992 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-03-28T16:55:51Z\n",
            "I0328 16:55:51.508042 140610591364992 evaluation.py:255] Starting evaluation at 2020-03-28T16:55:51Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0328 16:55:51.768348 140610591364992 monitored_session.py:240] Graph was finalized.\n",
            "2020-03-28 16:55:51.769135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 16:55:51.769560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-03-28 16:55:51.769646: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-03-28 16:55:51.769663: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-03-28 16:55:51.769676: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-03-28 16:55:51.769689: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-03-28 16:55:51.769704: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-03-28 16:55:51.769723: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-03-28 16:55:51.769746: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-03-28 16:55:51.769826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 16:55:51.770264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 16:55:51.770611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-03-28 16:55:51.770680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-03-28 16:55:51.770691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-03-28 16:55:51.770699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-03-28 16:55:51.770770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 16:55:51.771150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 16:55:51.771499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14889 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-15416\n",
            "I0328 16:55:51.773647 140610591364992 saver.py:1284] Restoring parameters from /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-15416\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0328 16:55:52.518790 140610591364992 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0328 16:55:52.647750 140610591364992 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 31 images.\n",
            "I0328 16:55:57.939538 140608248014592 coco_evaluation.py:205] Performing evaluation on 31 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0328 16:55:57.939970 140608248014592 coco_tools.py:115] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0328 16:55:57.941785 140608248014592 coco_tools.py:137] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.27s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.608\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.348\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.018\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.189\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.273\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.362\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.387\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.387\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.044\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.227\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.291\n",
            "INFO:tensorflow:Finished evaluation at 2020-03-28-16:55:59\n",
            "I0328 16:55:59.887185 140610591364992 evaluation.py:275] Finished evaluation at 2020-03-28-16:55:59\n",
            "INFO:tensorflow:Saving dict for global step 15416: DetectionBoxes_Precision/mAP = 0.3438376, DetectionBoxes_Precision/mAP (large) = 0.2734553, DetectionBoxes_Precision/mAP (medium) = 0.18886305, DetectionBoxes_Precision/mAP (small) = 0.017892504, DetectionBoxes_Precision/mAP@.50IOU = 0.60757005, DetectionBoxes_Precision/mAP@.75IOU = 0.3479706, DetectionBoxes_Recall/AR@1 = 0.361657, DetectionBoxes_Recall/AR@10 = 0.38743824, DetectionBoxes_Recall/AR@100 = 0.38743824, DetectionBoxes_Recall/AR@100 (large) = 0.29089028, DetectionBoxes_Recall/AR@100 (medium) = 0.22697811, DetectionBoxes_Recall/AR@100 (small) = 0.04375, Loss/classification_loss = 5.298955, Loss/localization_loss = 1.9601582, Loss/regularization_loss = 0.3465115, Loss/total_loss = 7.605625, global_step = 15416, learning_rate = 0.004, loss = 7.605625\n",
            "I0328 16:55:59.887471 140610591364992 estimator.py:2049] Saving dict for global step 15416: DetectionBoxes_Precision/mAP = 0.3438376, DetectionBoxes_Precision/mAP (large) = 0.2734553, DetectionBoxes_Precision/mAP (medium) = 0.18886305, DetectionBoxes_Precision/mAP (small) = 0.017892504, DetectionBoxes_Precision/mAP@.50IOU = 0.60757005, DetectionBoxes_Precision/mAP@.75IOU = 0.3479706, DetectionBoxes_Recall/AR@1 = 0.361657, DetectionBoxes_Recall/AR@10 = 0.38743824, DetectionBoxes_Recall/AR@100 = 0.38743824, DetectionBoxes_Recall/AR@100 (large) = 0.29089028, DetectionBoxes_Recall/AR@100 (medium) = 0.22697811, DetectionBoxes_Recall/AR@100 (small) = 0.04375, Loss/classification_loss = 5.298955, Loss/localization_loss = 1.9601582, Loss/regularization_loss = 0.3465115, Loss/total_loss = 7.605625, global_step = 15416, learning_rate = 0.004, loss = 7.605625\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 15416: /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-15416\n",
            "I0328 16:55:59.897565 140610591364992 estimator.py:2109] Saving 'checkpoint_path' summary for global step 15416: /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-15416\n",
            "INFO:tensorflow:global_step/sec: 1.23931\n",
            "I0328 16:56:29.646415 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.23931\n",
            "INFO:tensorflow:loss = 1.2553378, step = 15459 (80.690 sec)\n",
            "I0328 16:56:29.647542 140610591364992 basic_session_run_hooks.py:260] loss = 1.2553378, step = 15459 (80.690 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.45966\n",
            "I0328 16:57:38.155570 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.45966\n",
            "INFO:tensorflow:loss = 1.2086332, step = 15559 (68.510 sec)\n",
            "I0328 16:57:38.157786 140610591364992 basic_session_run_hooks.py:260] loss = 1.2086332, step = 15559 (68.510 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.45745\n",
            "I0328 16:58:46.768748 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.45745\n",
            "INFO:tensorflow:loss = 1.2601216, step = 15659 (68.612 sec)\n",
            "I0328 16:58:46.769686 140610591364992 basic_session_run_hooks.py:260] loss = 1.2601216, step = 15659 (68.612 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.46226\n",
            "I0328 16:59:55.156118 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.46226\n",
            "INFO:tensorflow:loss = 1.3049608, step = 15759 (68.388 sec)\n",
            "I0328 16:59:55.157803 140610591364992 basic_session_run_hooks.py:260] loss = 1.3049608, step = 15759 (68.388 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.47551\n",
            "I0328 17:01:02.929047 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.47551\n",
            "INFO:tensorflow:loss = 1.8112121, step = 15859 (67.772 sec)\n",
            "I0328 17:01:02.930066 140610591364992 basic_session_run_hooks.py:260] loss = 1.8112121, step = 15859 (67.772 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.47828\n",
            "I0328 17:02:10.575315 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.47828\n",
            "INFO:tensorflow:loss = 1.6256596, step = 15959 (67.647 sec)\n",
            "I0328 17:02:10.577104 140610591364992 basic_session_run_hooks.py:260] loss = 1.6256596, step = 15959 (67.647 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.45698\n",
            "I0328 17:03:19.210334 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.45698\n",
            "INFO:tensorflow:loss = 1.1466017, step = 16059 (68.634 sec)\n",
            "I0328 17:03:19.211530 140610591364992 basic_session_run_hooks.py:260] loss = 1.1466017, step = 16059 (68.634 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.46345\n",
            "I0328 17:04:27.542069 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.46345\n",
            "INFO:tensorflow:loss = 1.5312669, step = 16159 (68.332 sec)\n",
            "I0328 17:04:27.543846 140610591364992 basic_session_run_hooks.py:260] loss = 1.5312669, step = 16159 (68.332 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.45654\n",
            "I0328 17:05:36.197960 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.45654\n",
            "INFO:tensorflow:loss = 2.0753486, step = 16259 (68.655 sec)\n",
            "I0328 17:05:36.198971 140610591364992 basic_session_run_hooks.py:260] loss = 2.0753486, step = 16259 (68.655 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 16275 into /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt.\n",
            "I0328 17:05:46.516944 140610591364992 basic_session_run_hooks.py:606] Saving checkpoints for 16275 into /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0328 17:05:48.968284 140610591364992 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:05:50.376956 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:05:50.407335 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:05:50.437190 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:05:50.465927 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:05:50.493958 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:05:50.523738 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0328 17:05:51.855017 140610591364992 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-03-28T17:05:51Z\n",
            "I0328 17:05:51.871127 140610591364992 evaluation.py:255] Starting evaluation at 2020-03-28T17:05:51Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0328 17:05:52.135958 140610591364992 monitored_session.py:240] Graph was finalized.\n",
            "2020-03-28 17:05:52.137436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:05:52.138051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-03-28 17:05:52.138205: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-03-28 17:05:52.138243: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-03-28 17:05:52.138268: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-03-28 17:05:52.138291: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-03-28 17:05:52.138454: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-03-28 17:05:52.138544: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-03-28 17:05:52.138582: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-03-28 17:05:52.138691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:05:52.139346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:05:52.139863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-03-28 17:05:52.140049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-03-28 17:05:52.140070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-03-28 17:05:52.140097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-03-28 17:05:52.140214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:05:52.140849: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:05:52.141496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14889 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-16275\n",
            "I0328 17:05:52.144665 140610591364992 saver.py:1284] Restoring parameters from /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-16275\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0328 17:05:52.901312 140610591364992 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0328 17:05:53.069415 140610591364992 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 31 images.\n",
            "I0328 17:05:58.686468 140608248014592 coco_evaluation.py:205] Performing evaluation on 31 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0328 17:05:58.687113 140608248014592 coco_tools.py:115] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0328 17:05:58.690019 140608248014592 coco_tools.py:137] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.26s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.07s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.382\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.692\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.371\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.041\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.287\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.536\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.397\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.460\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.460\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.062\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.381\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.564\n",
            "INFO:tensorflow:Finished evaluation at 2020-03-28-17:06:00\n",
            "I0328 17:06:00.625775 140610591364992 evaluation.py:275] Finished evaluation at 2020-03-28-17:06:00\n",
            "INFO:tensorflow:Saving dict for global step 16275: DetectionBoxes_Precision/mAP = 0.3823803, DetectionBoxes_Precision/mAP (large) = 0.5360598, DetectionBoxes_Precision/mAP (medium) = 0.2874716, DetectionBoxes_Precision/mAP (small) = 0.041458145, DetectionBoxes_Precision/mAP@.50IOU = 0.6923762, DetectionBoxes_Precision/mAP@.75IOU = 0.37088984, DetectionBoxes_Recall/AR@1 = 0.39718688, DetectionBoxes_Recall/AR@10 = 0.4604681, DetectionBoxes_Recall/AR@100 = 0.4604681, DetectionBoxes_Recall/AR@100 (large) = 0.56444097, DetectionBoxes_Recall/AR@100 (medium) = 0.38118687, DetectionBoxes_Recall/AR@100 (small) = 0.0625, Loss/classification_loss = 3.692205, Loss/localization_loss = 1.6926824, Loss/regularization_loss = 0.34629562, Loss/total_loss = 5.731182, global_step = 16275, learning_rate = 0.004, loss = 5.731182\n",
            "I0328 17:06:00.626119 140610591364992 estimator.py:2049] Saving dict for global step 16275: DetectionBoxes_Precision/mAP = 0.3823803, DetectionBoxes_Precision/mAP (large) = 0.5360598, DetectionBoxes_Precision/mAP (medium) = 0.2874716, DetectionBoxes_Precision/mAP (small) = 0.041458145, DetectionBoxes_Precision/mAP@.50IOU = 0.6923762, DetectionBoxes_Precision/mAP@.75IOU = 0.37088984, DetectionBoxes_Recall/AR@1 = 0.39718688, DetectionBoxes_Recall/AR@10 = 0.4604681, DetectionBoxes_Recall/AR@100 = 0.4604681, DetectionBoxes_Recall/AR@100 (large) = 0.56444097, DetectionBoxes_Recall/AR@100 (medium) = 0.38118687, DetectionBoxes_Recall/AR@100 (small) = 0.0625, Loss/classification_loss = 3.692205, Loss/localization_loss = 1.6926824, Loss/regularization_loss = 0.34629562, Loss/total_loss = 5.731182, global_step = 16275, learning_rate = 0.004, loss = 5.731182\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 16275: /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-16275\n",
            "I0328 17:06:00.636554 140610591364992 estimator.py:2109] Saving 'checkpoint_path' summary for global step 16275: /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-16275\n",
            "INFO:tensorflow:global_step/sec: 1.20556\n",
            "I0328 17:06:59.146934 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.20556\n",
            "INFO:tensorflow:loss = 1.6129725, step = 16359 (82.950 sec)\n",
            "I0328 17:06:59.148660 140610591364992 basic_session_run_hooks.py:260] loss = 1.6129725, step = 16359 (82.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.46227\n",
            "I0328 17:08:07.533909 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.46227\n",
            "INFO:tensorflow:loss = 1.630988, step = 16459 (68.386 sec)\n",
            "I0328 17:08:07.535153 140610591364992 basic_session_run_hooks.py:260] loss = 1.630988, step = 16459 (68.386 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.47128\n",
            "I0328 17:09:15.502031 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.47128\n",
            "INFO:tensorflow:loss = 1.9728094, step = 16559 (67.968 sec)\n",
            "I0328 17:09:15.503508 140610591364992 basic_session_run_hooks.py:260] loss = 1.9728094, step = 16559 (67.968 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.47196\n",
            "I0328 17:10:23.438480 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.47196\n",
            "INFO:tensorflow:loss = 1.4584862, step = 16659 (67.936 sec)\n",
            "I0328 17:10:23.439575 140610591364992 basic_session_run_hooks.py:260] loss = 1.4584862, step = 16659 (67.936 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.4858\n",
            "I0328 17:11:30.742103 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.4858\n",
            "INFO:tensorflow:loss = 0.9192164, step = 16759 (67.304 sec)\n",
            "I0328 17:11:30.743767 140610591364992 basic_session_run_hooks.py:260] loss = 0.9192164, step = 16759 (67.304 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.47787\n",
            "I0328 17:12:38.407286 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.47787\n",
            "INFO:tensorflow:loss = 1.7035431, step = 16859 (67.665 sec)\n",
            "I0328 17:12:38.408368 140610591364992 basic_session_run_hooks.py:260] loss = 1.7035431, step = 16859 (67.665 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.47553\n",
            "I0328 17:13:46.179675 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.47553\n",
            "INFO:tensorflow:loss = 1.4834125, step = 16959 (67.773 sec)\n",
            "I0328 17:13:46.181114 140610591364992 basic_session_run_hooks.py:260] loss = 1.4834125, step = 16959 (67.773 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.47502\n",
            "I0328 17:14:53.975356 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.47502\n",
            "INFO:tensorflow:loss = 1.3390484, step = 17059 (67.795 sec)\n",
            "I0328 17:14:53.976358 140610591364992 basic_session_run_hooks.py:260] loss = 1.3390484, step = 17059 (67.795 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 17139 into /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt.\n",
            "I0328 17:15:46.713612 140610591364992 basic_session_run_hooks.py:606] Saving checkpoints for 17139 into /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0328 17:15:48.813917 140610591364992 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:15:50.196201 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:15:50.225277 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:15:50.253884 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:15:50.282915 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:15:50.317390 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:15:50.345503 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0328 17:15:51.649205 140610591364992 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-03-28T17:15:51Z\n",
            "I0328 17:15:51.664541 140610591364992 evaluation.py:255] Starting evaluation at 2020-03-28T17:15:51Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0328 17:15:51.925889 140610591364992 monitored_session.py:240] Graph was finalized.\n",
            "2020-03-28 17:15:51.926607: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:15:51.927038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-03-28 17:15:51.927196: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-03-28 17:15:51.927233: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-03-28 17:15:51.927257: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-03-28 17:15:51.927282: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-03-28 17:15:51.927307: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-03-28 17:15:51.927328: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-03-28 17:15:51.927350: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-03-28 17:15:51.927432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:15:51.927840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:15:51.928259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-03-28 17:15:51.928341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-03-28 17:15:51.928357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-03-28 17:15:51.928366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-03-28 17:15:51.928475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:15:51.928876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:15:51.929251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14889 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-17139\n",
            "I0328 17:15:51.931292 140610591364992 saver.py:1284] Restoring parameters from /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-17139\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0328 17:15:52.585852 140610591364992 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0328 17:15:52.681817 140610591364992 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 31 images.\n",
            "I0328 17:15:58.443552 140608248014592 coco_evaluation.py:205] Performing evaluation on 31 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0328 17:15:58.444483 140608248014592 coco_tools.py:115] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0328 17:15:58.446633 140608248014592 coco_tools.py:137] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.27s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.379\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.683\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.333\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.012\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.280\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.515\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.374\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.440\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.440\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.025\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.364\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.535\n",
            "INFO:tensorflow:Finished evaluation at 2020-03-28-17:16:00\n",
            "I0328 17:16:00.358731 140610591364992 evaluation.py:275] Finished evaluation at 2020-03-28-17:16:00\n",
            "INFO:tensorflow:Saving dict for global step 17139: DetectionBoxes_Precision/mAP = 0.3790771, DetectionBoxes_Precision/mAP (large) = 0.51496327, DetectionBoxes_Precision/mAP (medium) = 0.28036737, DetectionBoxes_Precision/mAP (small) = 0.0118811885, DetectionBoxes_Precision/mAP@.50IOU = 0.6834329, DetectionBoxes_Precision/mAP@.75IOU = 0.33253375, DetectionBoxes_Recall/AR@1 = 0.37391022, DetectionBoxes_Recall/AR@10 = 0.44037658, DetectionBoxes_Recall/AR@100 = 0.44037658, DetectionBoxes_Recall/AR@100 (large) = 0.53473085, DetectionBoxes_Recall/AR@100 (medium) = 0.36359426, DetectionBoxes_Recall/AR@100 (small) = 0.025, Loss/classification_loss = 4.3030376, Loss/localization_loss = 1.7321743, Loss/regularization_loss = 0.34609345, Loss/total_loss = 6.381305, global_step = 17139, learning_rate = 0.004, loss = 6.381305\n",
            "I0328 17:16:00.359009 140610591364992 estimator.py:2049] Saving dict for global step 17139: DetectionBoxes_Precision/mAP = 0.3790771, DetectionBoxes_Precision/mAP (large) = 0.51496327, DetectionBoxes_Precision/mAP (medium) = 0.28036737, DetectionBoxes_Precision/mAP (small) = 0.0118811885, DetectionBoxes_Precision/mAP@.50IOU = 0.6834329, DetectionBoxes_Precision/mAP@.75IOU = 0.33253375, DetectionBoxes_Recall/AR@1 = 0.37391022, DetectionBoxes_Recall/AR@10 = 0.44037658, DetectionBoxes_Recall/AR@100 = 0.44037658, DetectionBoxes_Recall/AR@100 (large) = 0.53473085, DetectionBoxes_Recall/AR@100 (medium) = 0.36359426, DetectionBoxes_Recall/AR@100 (small) = 0.025, Loss/classification_loss = 4.3030376, Loss/localization_loss = 1.7321743, Loss/regularization_loss = 0.34609345, Loss/total_loss = 6.381305, global_step = 17139, learning_rate = 0.004, loss = 6.381305\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 17139: /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-17139\n",
            "I0328 17:16:00.369277 140610591364992 estimator.py:2109] Saving 'checkpoint_path' summary for global step 17139: /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-17139\n",
            "INFO:tensorflow:global_step/sec: 1.24254\n",
            "I0328 17:16:14.455772 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.24254\n",
            "INFO:tensorflow:loss = 2.0110865, step = 17159 (80.481 sec)\n",
            "I0328 17:16:14.456905 140610591364992 basic_session_run_hooks.py:260] loss = 2.0110865, step = 17159 (80.481 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.48723\n",
            "I0328 17:17:21.695036 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.48723\n",
            "INFO:tensorflow:loss = 1.604058, step = 17259 (67.239 sec)\n",
            "I0328 17:17:21.696045 140610591364992 basic_session_run_hooks.py:260] loss = 1.604058, step = 17259 (67.239 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.48861\n",
            "I0328 17:18:28.871655 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.48861\n",
            "INFO:tensorflow:loss = 1.9249954, step = 17359 (67.177 sec)\n",
            "I0328 17:18:28.873231 140610591364992 basic_session_run_hooks.py:260] loss = 1.9249954, step = 17359 (67.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.49453\n",
            "I0328 17:19:35.782400 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.49453\n",
            "INFO:tensorflow:loss = 1.2106422, step = 17459 (66.910 sec)\n",
            "I0328 17:19:35.783335 140610591364992 basic_session_run_hooks.py:260] loss = 1.2106422, step = 17459 (66.910 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.48936\n",
            "I0328 17:20:42.925497 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.48936\n",
            "INFO:tensorflow:loss = 1.9529905, step = 17559 (67.144 sec)\n",
            "I0328 17:20:42.926985 140610591364992 basic_session_run_hooks.py:260] loss = 1.9529905, step = 17559 (67.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.49646\n",
            "I0328 17:21:49.749953 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.49646\n",
            "INFO:tensorflow:loss = 1.274401, step = 17659 (66.824 sec)\n",
            "I0328 17:21:49.751119 140610591364992 basic_session_run_hooks.py:260] loss = 1.274401, step = 17659 (66.824 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.49449\n",
            "I0328 17:22:56.662590 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.49449\n",
            "INFO:tensorflow:loss = 1.2023379, step = 17759 (66.913 sec)\n",
            "I0328 17:22:56.664397 140610591364992 basic_session_run_hooks.py:260] loss = 1.2023379, step = 17759 (66.913 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.48302\n",
            "I0328 17:24:04.092673 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.48302\n",
            "INFO:tensorflow:loss = 1.9538443, step = 17859 (67.429 sec)\n",
            "I0328 17:24:04.093707 140610591364992 basic_session_run_hooks.py:260] loss = 1.9538443, step = 17859 (67.429 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.47829\n",
            "I0328 17:25:11.738499 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.47829\n",
            "INFO:tensorflow:loss = 1.106662, step = 17959 (67.647 sec)\n",
            "I0328 17:25:11.740287 140610591364992 basic_session_run_hooks.py:260] loss = 1.106662, step = 17959 (67.647 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 18012 into /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt.\n",
            "I0328 17:25:47.099041 140610591364992 basic_session_run_hooks.py:606] Saving checkpoints for 18012 into /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0328 17:25:49.243814 140610591364992 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:25:50.624424 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:25:50.653275 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:25:50.680816 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:25:50.708357 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:25:50.744869 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:25:50.792521 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0328 17:25:52.092460 140610591364992 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-03-28T17:25:52Z\n",
            "I0328 17:25:52.108485 140610591364992 evaluation.py:255] Starting evaluation at 2020-03-28T17:25:52Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0328 17:25:52.364800 140610591364992 monitored_session.py:240] Graph was finalized.\n",
            "2020-03-28 17:25:52.365466: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:25:52.365882: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-03-28 17:25:52.365963: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-03-28 17:25:52.365979: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-03-28 17:25:52.365992: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-03-28 17:25:52.366005: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-03-28 17:25:52.366022: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-03-28 17:25:52.366034: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-03-28 17:25:52.366048: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-03-28 17:25:52.366157: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:25:52.366557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:25:52.366889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-03-28 17:25:52.366958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-03-28 17:25:52.366969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-03-28 17:25:52.366977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-03-28 17:25:52.367050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:25:52.367509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:25:52.367871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14889 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-18012\n",
            "I0328 17:25:52.370063 140610591364992 saver.py:1284] Restoring parameters from /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-18012\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0328 17:25:53.077103 140610591364992 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0328 17:25:53.189650 140610591364992 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 31 images.\n",
            "I0328 17:25:58.842529 140608136017664 coco_evaluation.py:205] Performing evaluation on 31 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0328 17:25:58.843326 140608136017664 coco_tools.py:115] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0328 17:25:58.844909 140608136017664 coco_tools.py:137] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.28s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.07s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.365\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.711\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.324\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.048\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.288\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.492\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.372\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.441\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.441\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.094\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.381\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.525\n",
            "INFO:tensorflow:Finished evaluation at 2020-03-28-17:26:00\n",
            "I0328 17:26:00.749063 140610591364992 evaluation.py:275] Finished evaluation at 2020-03-28-17:26:00\n",
            "INFO:tensorflow:Saving dict for global step 18012: DetectionBoxes_Precision/mAP = 0.36463666, DetectionBoxes_Precision/mAP (large) = 0.4916137, DetectionBoxes_Precision/mAP (medium) = 0.288035, DetectionBoxes_Precision/mAP (small) = 0.047821783, DetectionBoxes_Precision/mAP@.50IOU = 0.710839, DetectionBoxes_Precision/mAP@.75IOU = 0.32414338, DetectionBoxes_Recall/AR@1 = 0.37154546, DetectionBoxes_Recall/AR@10 = 0.4410166, DetectionBoxes_Recall/AR@100 = 0.4410166, DetectionBoxes_Recall/AR@100 (large) = 0.5250518, DetectionBoxes_Recall/AR@100 (medium) = 0.38148147, DetectionBoxes_Recall/AR@100 (small) = 0.09375, Loss/classification_loss = 2.9487476, Loss/localization_loss = 1.7953992, Loss/regularization_loss = 0.34585604, Loss/total_loss = 5.0900025, global_step = 18012, learning_rate = 0.004, loss = 5.0900025\n",
            "I0328 17:26:00.749403 140610591364992 estimator.py:2049] Saving dict for global step 18012: DetectionBoxes_Precision/mAP = 0.36463666, DetectionBoxes_Precision/mAP (large) = 0.4916137, DetectionBoxes_Precision/mAP (medium) = 0.288035, DetectionBoxes_Precision/mAP (small) = 0.047821783, DetectionBoxes_Precision/mAP@.50IOU = 0.710839, DetectionBoxes_Precision/mAP@.75IOU = 0.32414338, DetectionBoxes_Recall/AR@1 = 0.37154546, DetectionBoxes_Recall/AR@10 = 0.4410166, DetectionBoxes_Recall/AR@100 = 0.4410166, DetectionBoxes_Recall/AR@100 (large) = 0.5250518, DetectionBoxes_Recall/AR@100 (medium) = 0.38148147, DetectionBoxes_Recall/AR@100 (small) = 0.09375, Loss/classification_loss = 2.9487476, Loss/localization_loss = 1.7953992, Loss/regularization_loss = 0.34585604, Loss/total_loss = 5.0900025, global_step = 18012, learning_rate = 0.004, loss = 5.0900025\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 18012: /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-18012\n",
            "I0328 17:26:00.759330 140610591364992 estimator.py:2109] Saving 'checkpoint_path' summary for global step 18012: /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-18012\n",
            "INFO:tensorflow:global_step/sec: 1.22503\n",
            "I0328 17:26:33.369459 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.22503\n",
            "INFO:tensorflow:loss = 1.3811619, step = 18059 (81.630 sec)\n",
            "I0328 17:26:33.370448 140610591364992 basic_session_run_hooks.py:260] loss = 1.3811619, step = 18059 (81.630 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.47567\n",
            "I0328 17:27:41.135417 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.47567\n",
            "INFO:tensorflow:loss = 1.0795934, step = 18159 (67.767 sec)\n",
            "I0328 17:27:41.137667 140610591364992 basic_session_run_hooks.py:260] loss = 1.0795934, step = 18159 (67.767 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.4752\n",
            "I0328 17:28:48.922654 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.4752\n",
            "INFO:tensorflow:loss = 1.9152678, step = 18259 (67.786 sec)\n",
            "I0328 17:28:48.923768 140610591364992 basic_session_run_hooks.py:260] loss = 1.9152678, step = 18259 (67.786 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.48256\n",
            "I0328 17:29:56.373653 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.48256\n",
            "INFO:tensorflow:loss = 1.7951422, step = 18359 (67.452 sec)\n",
            "I0328 17:29:56.375461 140610591364992 basic_session_run_hooks.py:260] loss = 1.7951422, step = 18359 (67.452 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.47911\n",
            "I0328 17:31:03.981790 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.47911\n",
            "INFO:tensorflow:loss = 1.4519966, step = 18459 (67.608 sec)\n",
            "I0328 17:31:03.982971 140610591364992 basic_session_run_hooks.py:260] loss = 1.4519966, step = 18459 (67.608 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.48505\n",
            "I0328 17:32:11.319372 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.48505\n",
            "INFO:tensorflow:loss = 1.6664609, step = 18559 (67.338 sec)\n",
            "I0328 17:32:11.320959 140610591364992 basic_session_run_hooks.py:260] loss = 1.6664609, step = 18559 (67.338 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.48283\n",
            "I0328 17:33:18.757846 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.48283\n",
            "INFO:tensorflow:loss = 1.2869589, step = 18659 (67.438 sec)\n",
            "I0328 17:33:18.758769 140610591364992 basic_session_run_hooks.py:260] loss = 1.2869589, step = 18659 (67.438 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.47629\n",
            "I0328 17:34:26.495195 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.47629\n",
            "INFO:tensorflow:loss = 1.674065, step = 18759 (67.738 sec)\n",
            "I0328 17:34:26.496722 140610591364992 basic_session_run_hooks.py:260] loss = 1.674065, step = 18759 (67.738 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.45489\n",
            "I0328 17:35:35.228654 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.45489\n",
            "INFO:tensorflow:loss = 1.3423433, step = 18859 (68.733 sec)\n",
            "I0328 17:35:35.229798 140610591364992 basic_session_run_hooks.py:260] loss = 1.3423433, step = 18859 (68.733 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 18878 into /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt.\n",
            "I0328 17:35:47.863274 140610591364992 basic_session_run_hooks.py:606] Saving checkpoints for 18878 into /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0328 17:35:50.146126 140610591364992 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:35:51.602051 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:35:51.636341 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:35:51.667366 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:35:51.697705 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:35:51.728861 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:35:51.760371 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0328 17:35:53.136451 140610591364992 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-03-28T17:35:53Z\n",
            "I0328 17:35:53.152280 140610591364992 evaluation.py:255] Starting evaluation at 2020-03-28T17:35:53Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0328 17:35:53.428864 140610591364992 monitored_session.py:240] Graph was finalized.\n",
            "2020-03-28 17:35:53.429680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:35:53.430238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-03-28 17:35:53.430331: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-03-28 17:35:53.430352: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-03-28 17:35:53.430367: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-03-28 17:35:53.430383: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-03-28 17:35:53.430397: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-03-28 17:35:53.430410: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-03-28 17:35:53.430425: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-03-28 17:35:53.430493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:35:53.430879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:35:53.431248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-03-28 17:35:53.431318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-03-28 17:35:53.431329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-03-28 17:35:53.431339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-03-28 17:35:53.431426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:35:53.431830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:35:53.432266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14889 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-18878\n",
            "I0328 17:35:53.434513 140610591364992 saver.py:1284] Restoring parameters from /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-18878\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0328 17:35:54.161432 140610591364992 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0328 17:35:54.285393 140610591364992 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 31 images.\n",
            "I0328 17:36:00.703668 140608248014592 coco_evaluation.py:205] Performing evaluation on 31 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0328 17:36:00.704199 140608248014592 coco_tools.py:115] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0328 17:36:00.707201 140608248014592 coco_tools.py:137] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.30s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.07s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.339\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.672\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.316\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.029\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.285\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.261\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.323\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.387\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.387\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.031\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.334\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.286\n",
            "INFO:tensorflow:Finished evaluation at 2020-03-28-17:36:02\n",
            "I0328 17:36:02.822716 140610591364992 evaluation.py:275] Finished evaluation at 2020-03-28-17:36:02\n",
            "INFO:tensorflow:Saving dict for global step 18878: DetectionBoxes_Precision/mAP = 0.33866057, DetectionBoxes_Precision/mAP (large) = 0.26076007, DetectionBoxes_Precision/mAP (medium) = 0.28452152, DetectionBoxes_Precision/mAP (small) = 0.02891089, DetectionBoxes_Precision/mAP@.50IOU = 0.67249155, DetectionBoxes_Precision/mAP@.75IOU = 0.3159084, DetectionBoxes_Recall/AR@1 = 0.32298118, DetectionBoxes_Recall/AR@10 = 0.38704368, DetectionBoxes_Recall/AR@100 = 0.38704368, DetectionBoxes_Recall/AR@100 (large) = 0.28561077, DetectionBoxes_Recall/AR@100 (medium) = 0.33434343, DetectionBoxes_Recall/AR@100 (small) = 0.03125, Loss/classification_loss = 3.422997, Loss/localization_loss = 1.9863087, Loss/regularization_loss = 0.34559813, Loss/total_loss = 5.754902, global_step = 18878, learning_rate = 0.004, loss = 5.754902\n",
            "I0328 17:36:02.823050 140610591364992 estimator.py:2049] Saving dict for global step 18878: DetectionBoxes_Precision/mAP = 0.33866057, DetectionBoxes_Precision/mAP (large) = 0.26076007, DetectionBoxes_Precision/mAP (medium) = 0.28452152, DetectionBoxes_Precision/mAP (small) = 0.02891089, DetectionBoxes_Precision/mAP@.50IOU = 0.67249155, DetectionBoxes_Precision/mAP@.75IOU = 0.3159084, DetectionBoxes_Recall/AR@1 = 0.32298118, DetectionBoxes_Recall/AR@10 = 0.38704368, DetectionBoxes_Recall/AR@100 = 0.38704368, DetectionBoxes_Recall/AR@100 (large) = 0.28561077, DetectionBoxes_Recall/AR@100 (medium) = 0.33434343, DetectionBoxes_Recall/AR@100 (small) = 0.03125, Loss/classification_loss = 3.422997, Loss/localization_loss = 1.9863087, Loss/regularization_loss = 0.34559813, Loss/total_loss = 5.754902, global_step = 18878, learning_rate = 0.004, loss = 5.754902\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 18878: /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-18878\n",
            "I0328 17:36:02.833614 140610591364992 estimator.py:2109] Saving 'checkpoint_path' summary for global step 18878: /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-18878\n",
            "INFO:tensorflow:global_step/sec: 1.15711\n",
            "I0328 17:37:01.650643 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.15711\n",
            "INFO:tensorflow:loss = 1.4058946, step = 18959 (86.423 sec)\n",
            "I0328 17:37:01.652480 140610591364992 basic_session_run_hooks.py:260] loss = 1.4058946, step = 18959 (86.423 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.43514\n",
            "I0328 17:38:11.330474 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.43514\n",
            "INFO:tensorflow:loss = 1.5597832, step = 19059 (69.679 sec)\n",
            "I0328 17:38:11.331750 140610591364992 basic_session_run_hooks.py:260] loss = 1.5597832, step = 19059 (69.679 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.44432\n",
            "I0328 17:39:20.567269 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.44432\n",
            "INFO:tensorflow:loss = 1.4909555, step = 19159 (69.237 sec)\n",
            "I0328 17:39:20.568629 140610591364992 basic_session_run_hooks.py:260] loss = 1.4909555, step = 19159 (69.237 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.46225\n",
            "I0328 17:40:28.954872 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.46225\n",
            "INFO:tensorflow:loss = 1.0781462, step = 19259 (68.387 sec)\n",
            "I0328 17:40:28.955913 140610591364992 basic_session_run_hooks.py:260] loss = 1.0781462, step = 19259 (68.387 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.47135\n",
            "I0328 17:41:36.919581 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.47135\n",
            "INFO:tensorflow:loss = 2.1534975, step = 19359 (67.965 sec)\n",
            "I0328 17:41:36.921266 140610591364992 basic_session_run_hooks.py:260] loss = 2.1534975, step = 19359 (67.965 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.46592\n",
            "I0328 17:42:45.136336 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.46592\n",
            "INFO:tensorflow:loss = 2.0902371, step = 19459 (68.216 sec)\n",
            "I0328 17:42:45.137298 140610591364992 basic_session_run_hooks.py:260] loss = 2.0902371, step = 19459 (68.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.47857\n",
            "I0328 17:43:52.769251 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.47857\n",
            "INFO:tensorflow:loss = 1.8648868, step = 19559 (67.634 sec)\n",
            "I0328 17:43:52.770886 140610591364992 basic_session_run_hooks.py:260] loss = 1.8648868, step = 19559 (67.634 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.48082\n",
            "I0328 17:45:00.299515 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.48082\n",
            "INFO:tensorflow:loss = 1.1568542, step = 19659 (67.530 sec)\n",
            "I0328 17:45:00.300772 140610591364992 basic_session_run_hooks.py:260] loss = 1.1568542, step = 19659 (67.530 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 19731 into /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt.\n",
            "I0328 17:45:48.165428 140610591364992 basic_session_run_hooks.py:606] Saving checkpoints for 19731 into /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0328 17:45:50.321735 140610591364992 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:45:51.716292 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:45:51.744593 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:45:51.772465 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:45:51.800019 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:45:51.829201 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:45:51.857280 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0328 17:45:53.151496 140610591364992 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-03-28T17:45:53Z\n",
            "I0328 17:45:53.166981 140610591364992 evaluation.py:255] Starting evaluation at 2020-03-28T17:45:53Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0328 17:45:53.423517 140610591364992 monitored_session.py:240] Graph was finalized.\n",
            "2020-03-28 17:45:53.424869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:45:53.425472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-03-28 17:45:53.426111: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-03-28 17:45:53.426172: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-03-28 17:45:53.426202: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-03-28 17:45:53.426224: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-03-28 17:45:53.426243: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-03-28 17:45:53.426262: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-03-28 17:45:53.426283: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-03-28 17:45:53.426387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:45:53.427040: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:45:53.427638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-03-28 17:45:53.427900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-03-28 17:45:53.427927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-03-28 17:45:53.427942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-03-28 17:45:53.428069: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:45:53.428753: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:45:53.429310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14889 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-19731\n",
            "I0328 17:45:53.435319 140610591364992 saver.py:1284] Restoring parameters from /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-19731\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0328 17:45:54.133512 140610591364992 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0328 17:45:54.247866 140610591364992 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 31 images.\n",
            "I0328 17:45:59.946068 140608248014592 coco_evaluation.py:205] Performing evaluation on 31 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0328 17:45:59.947913 140608248014592 coco_tools.py:115] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0328 17:45:59.950638 140608248014592 coco_tools.py:137] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.26s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.06s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.366\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.638\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.415\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.017\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.295\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.493\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.355\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.419\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.419\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.037\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.344\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.522\n",
            "INFO:tensorflow:Finished evaluation at 2020-03-28-17:46:01\n",
            "I0328 17:46:01.862805 140610591364992 evaluation.py:275] Finished evaluation at 2020-03-28-17:46:01\n",
            "INFO:tensorflow:Saving dict for global step 19731: DetectionBoxes_Precision/mAP = 0.36582297, DetectionBoxes_Precision/mAP (large) = 0.4929644, DetectionBoxes_Precision/mAP (medium) = 0.2949116, DetectionBoxes_Precision/mAP (small) = 0.016855257, DetectionBoxes_Precision/mAP@.50IOU = 0.63813484, DetectionBoxes_Precision/mAP@.75IOU = 0.41509533, DetectionBoxes_Recall/AR@1 = 0.35543102, DetectionBoxes_Recall/AR@10 = 0.41949353, DetectionBoxes_Recall/AR@100 = 0.41949353, DetectionBoxes_Recall/AR@100 (large) = 0.52184266, DetectionBoxes_Recall/AR@100 (medium) = 0.34351853, DetectionBoxes_Recall/AR@100 (small) = 0.0375, Loss/classification_loss = 4.3642344, Loss/localization_loss = 1.8203315, Loss/regularization_loss = 0.3453779, Loss/total_loss = 6.529944, global_step = 19731, learning_rate = 0.004, loss = 6.529944\n",
            "I0328 17:46:01.863122 140610591364992 estimator.py:2049] Saving dict for global step 19731: DetectionBoxes_Precision/mAP = 0.36582297, DetectionBoxes_Precision/mAP (large) = 0.4929644, DetectionBoxes_Precision/mAP (medium) = 0.2949116, DetectionBoxes_Precision/mAP (small) = 0.016855257, DetectionBoxes_Precision/mAP@.50IOU = 0.63813484, DetectionBoxes_Precision/mAP@.75IOU = 0.41509533, DetectionBoxes_Recall/AR@1 = 0.35543102, DetectionBoxes_Recall/AR@10 = 0.41949353, DetectionBoxes_Recall/AR@100 = 0.41949353, DetectionBoxes_Recall/AR@100 (large) = 0.52184266, DetectionBoxes_Recall/AR@100 (medium) = 0.34351853, DetectionBoxes_Recall/AR@100 (small) = 0.0375, Loss/classification_loss = 4.3642344, Loss/localization_loss = 1.8203315, Loss/regularization_loss = 0.3453779, Loss/total_loss = 6.529944, global_step = 19731, learning_rate = 0.004, loss = 6.529944\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 19731: /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-19731\n",
            "I0328 17:46:01.873386 140610591364992 estimator.py:2109] Saving 'checkpoint_path' summary for global step 19731: /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-19731\n",
            "INFO:tensorflow:global_step/sec: 1.22885\n",
            "I0328 17:46:21.676314 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.22885\n",
            "INFO:tensorflow:loss = 1.4669688, step = 19759 (81.377 sec)\n",
            "I0328 17:46:21.677548 140610591364992 basic_session_run_hooks.py:260] loss = 1.4669688, step = 19759 (81.377 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.48067\n",
            "I0328 17:47:29.213498 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.48067\n",
            "INFO:tensorflow:loss = 1.567739, step = 19859 (67.537 sec)\n",
            "I0328 17:47:29.214560 140610591364992 basic_session_run_hooks.py:260] loss = 1.567739, step = 19859 (67.537 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.48081\n",
            "I0328 17:48:36.744281 140610591364992 basic_session_run_hooks.py:692] global_step/sec: 1.48081\n",
            "INFO:tensorflow:loss = 1.6813121, step = 19959 (67.531 sec)\n",
            "I0328 17:48:36.745981 140610591364992 basic_session_run_hooks.py:260] loss = 1.6813121, step = 19959 (67.531 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 20000 into /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt.\n",
            "I0328 17:49:03.841376 140610591364992 basic_session_run_hooks.py:606] Saving checkpoints for 20000 into /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "I0328 17:49:05.367427 140610591364992 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0328 17:49:06.002617 140610591364992 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:49:07.382448 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:49:07.410425 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:49:07.436912 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:49:07.464578 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:49:07.492002 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:49:07.518917 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0328 17:49:08.813496 140610591364992 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-03-28T17:49:08Z\n",
            "I0328 17:49:08.828755 140610591364992 evaluation.py:255] Starting evaluation at 2020-03-28T17:49:08Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0328 17:49:09.078794 140610591364992 monitored_session.py:240] Graph was finalized.\n",
            "2020-03-28 17:49:09.079500: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:49:09.079939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-03-28 17:49:09.080021: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-03-28 17:49:09.080037: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-03-28 17:49:09.080051: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-03-28 17:49:09.080063: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-03-28 17:49:09.080100: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-03-28 17:49:09.080124: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-03-28 17:49:09.080148: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-03-28 17:49:09.080213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:49:09.080631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:49:09.081055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-03-28 17:49:09.081131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-03-28 17:49:09.081143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-03-28 17:49:09.081151: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-03-28 17:49:09.081260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:49:09.081701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:49:09.082064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14889 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-20000\n",
            "I0328 17:49:09.084379 140610591364992 saver.py:1284] Restoring parameters from /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-20000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0328 17:49:09.808981 140610591364992 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0328 17:49:09.939849 140610591364992 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 31 images.\n",
            "I0328 17:49:15.828918 140608248014592 coco_evaluation.py:205] Performing evaluation on 31 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0328 17:49:15.829643 140608248014592 coco_tools.py:115] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0328 17:49:15.832890 140608248014592 coco_tools.py:137] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.26s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.07s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.396\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.641\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.384\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.047\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.304\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.481\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.393\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.453\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.453\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.087\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.347\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.516\n",
            "INFO:tensorflow:Finished evaluation at 2020-03-28-17:49:17\n",
            "I0328 17:49:17.741495 140610591364992 evaluation.py:275] Finished evaluation at 2020-03-28-17:49:17\n",
            "INFO:tensorflow:Saving dict for global step 20000: DetectionBoxes_Precision/mAP = 0.39610502, DetectionBoxes_Precision/mAP (large) = 0.48143932, DetectionBoxes_Precision/mAP (medium) = 0.30434898, DetectionBoxes_Precision/mAP (small) = 0.04722772, DetectionBoxes_Precision/mAP@.50IOU = 0.64085907, DetectionBoxes_Precision/mAP@.75IOU = 0.38388446, DetectionBoxes_Recall/AR@1 = 0.39349896, DetectionBoxes_Recall/AR@10 = 0.45287395, DetectionBoxes_Recall/AR@100 = 0.45287395, DetectionBoxes_Recall/AR@100 (large) = 0.515735, DetectionBoxes_Recall/AR@100 (medium) = 0.34743267, DetectionBoxes_Recall/AR@100 (small) = 0.0875, Loss/classification_loss = 4.1568446, Loss/localization_loss = 1.9732348, Loss/regularization_loss = 0.34529784, Loss/total_loss = 6.4753766, global_step = 20000, learning_rate = 0.004, loss = 6.4753766\n",
            "I0328 17:49:17.741822 140610591364992 estimator.py:2049] Saving dict for global step 20000: DetectionBoxes_Precision/mAP = 0.39610502, DetectionBoxes_Precision/mAP (large) = 0.48143932, DetectionBoxes_Precision/mAP (medium) = 0.30434898, DetectionBoxes_Precision/mAP (small) = 0.04722772, DetectionBoxes_Precision/mAP@.50IOU = 0.64085907, DetectionBoxes_Precision/mAP@.75IOU = 0.38388446, DetectionBoxes_Recall/AR@1 = 0.39349896, DetectionBoxes_Recall/AR@10 = 0.45287395, DetectionBoxes_Recall/AR@100 = 0.45287395, DetectionBoxes_Recall/AR@100 (large) = 0.515735, DetectionBoxes_Recall/AR@100 (medium) = 0.34743267, DetectionBoxes_Recall/AR@100 (small) = 0.0875, Loss/classification_loss = 4.1568446, Loss/localization_loss = 1.9732348, Loss/regularization_loss = 0.34529784, Loss/total_loss = 6.4753766, global_step = 20000, learning_rate = 0.004, loss = 6.4753766\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20000: /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-20000\n",
            "I0328 17:49:17.755640 140610591364992 estimator.py:2109] Saving 'checkpoint_path' summary for global step 20000: /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-20000\n",
            "INFO:tensorflow:Performing the final export in the end of training.\n",
            "I0328 17:49:17.756708 140610591364992 exporter.py:410] Performing the final export in the end of training.\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/inputs.py:750: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0328 17:49:17.768336 140610591364992 module_wrapper.py:139] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/inputs.py:750: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0328 17:49:17.966904 140610591364992 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:49:19.358521 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:49:19.387014 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:49:19.414177 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:49:19.441772 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:49:19.470318 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0328 17:49:19.499102 140610591364992 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/model_lib.py:426: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
            "\n",
            "W0328 17:49:19.989431 140610591364992 module_wrapper.py:139] From /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/model_lib.py:426: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0328 17:49:20.137892 140610591364992 estimator.py:1150] Done calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0328 17:49:20.138174 140610591364992 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "I0328 17:49:20.138783 140610591364992 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "I0328 17:49:20.138877 140610591364992 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "I0328 17:49:20.138932 140610591364992 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "I0328 17:49:20.138978 140610591364992 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "I0328 17:49:20.139020 140610591364992 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
            "2020-03-28 17:49:20.139526: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:49:20.139964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-03-28 17:49:20.140042: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-03-28 17:49:20.140057: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-03-28 17:49:20.140071: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-03-28 17:49:20.140114: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-03-28 17:49:20.140135: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-03-28 17:49:20.140156: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-03-28 17:49:20.140178: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-03-28 17:49:20.140261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:49:20.140662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:49:20.140996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-03-28 17:49:20.141029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-03-28 17:49:20.141039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-03-28 17:49:20.141047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-03-28 17:49:20.141133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:49:20.141499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-03-28 17:49:20.141849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14889 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-20000\n",
            "I0328 17:49:20.146059 140610591364992 saver.py:1284] Restoring parameters from /content/drive/My Drive/OBJ_Detect_POC/learning/trained/model.ckpt-20000\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "I0328 17:49:20.516904 140610591364992 builder_impl.py:665] Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0328 17:49:20.517126 140610591364992 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /content/drive/My Drive/OBJ_Detect_POC/learning/trained/export/Servo/temp-b'1585417757'/saved_model.pb\n",
            "I0328 17:49:21.171827 140610591364992 builder_impl.py:425] SavedModel written to: /content/drive/My Drive/OBJ_Detect_POC/learning/trained/export/Servo/temp-b'1585417757'/saved_model.pb\n",
            "INFO:tensorflow:Loss for final step: 1.7971442.\n",
            "I0328 17:49:21.513667 140610591364992 estimator.py:371] Loss for final step: 1.7971442.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2en1HF3k30Y",
        "colab_type": "text"
      },
      "source": [
        "##Finetune new trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsefU33_k_BZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd ~\n",
        "%cd /content\n",
        "%cd drive/My Drive/OBJ_Detect_POC/learning/\n",
        "import os\n",
        "lst = os.listdir('trained')\n",
        "lf = filter(lambda k: 'model.ckpt-' in k, lst)\n",
        "last_model = sorted(lf)[-1].replace('.meta', '')\n",
        "\n",
        "!python models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path=\"/content/drive/My Drive/OBJ_Detect_POC/learning/pipeline.config\" \\\n",
        "    --output_directory=fine_tuned_model \\\n",
        "    --trained_checkpoint_prefix=trained/$last_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9-79FKhBKVA",
        "colab_type": "text"
      },
      "source": [
        "## Functions needed for image object detection (image or video)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Raf7TS15BFp0",
        "colab_type": "code",
        "outputId": "9aeb2a8f-4f36-4f7b-b0c8-514219ad05ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#%cd ~\n",
        "%cd /content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "import subprocess\n",
        "import glob\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import PIL.ImageColor as ImageColor\n",
        "import PIL.ImageDraw as ImageDraw\n",
        "import PIL.ImageFont as ImageFont\n",
        "from moviepy.editor import AudioFileClip, CompositeAudioClip, concatenate_audioclips\n",
        "from moviepy.editor import *\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "\n",
        "# This is needed to display the images.\n",
        "%matplotlib inline\n",
        "\n",
        "from utils import label_map_util\n",
        "from utils import visualization_utils as vis_util\n",
        "\n",
        "class GameState:\n",
        "  #def __init__(self, name, age):\n",
        "  state = ''\n",
        "  transition = ''\n",
        "  audioPreviousTimeStamp = 0.0\n",
        "\n",
        "\n",
        "# function to get graph\n",
        "def setup_detection_graph(PATH_TO_CKPT):\n",
        "  detection_graph = tf.Graph()\n",
        "  with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "      serialized_graph = fid.read()\n",
        "      od_graph_def.ParseFromString(serialized_graph)\n",
        "      tf.import_graph_def(od_graph_def, name='')\n",
        "  \n",
        "  # print('CKPT=' + PATH_TO_CKPT)\n",
        "  return detection_graph\n",
        "\n",
        "def get_category_index(path_to_labels, num_classes):\n",
        "  label_map = label_map_util.load_labelmap(path_to_labels)\n",
        "  categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=num_classes, use_display_name=True)\n",
        "  category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "  return category_index\n",
        "\n",
        "# function for setting up COCO object detection\n",
        "def setup_coco_model():\n",
        "  #PATH_TO_CKPT = '/content/drive/My Drive/OBJ_Detect_POC/learning/image_test/pretrained_model/' + 'frozen_inference_graph.pb'\n",
        "  PATH_TO_CKPT = '/content/drive/My Drive/OBJ_Detect_POC/learning/pretrained_model_rcnn/' + 'frozen_inference_graph.pb'\n",
        "  return setup_detection_graph(PATH_TO_CKPT)\n",
        "  \n",
        "# function for setting up basketball specific object detection\n",
        "def setup_bball_model():\n",
        "  PATH_TO_CKPT = '/content/drive/My Drive/OBJ_Detect_POC/learning/fine_tuned_model/' + 'frozen_inference_graph.pb'\n",
        "  return setup_detection_graph(PATH_TO_CKPT)\n",
        "\n",
        "# function for putting image into numpy arraw\n",
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# function\n",
        "def run_inference_for_single_image(image, graph):\n",
        "  with graph.as_default():\n",
        "    with tf.Session() as sess:\n",
        "      # Get handles to input and output tensors\n",
        "      ops = tf.get_default_graph().get_operations()\n",
        "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "      tensor_dict = {}\n",
        "      for key in [\n",
        "          'num_detections', 'detection_boxes', 'detection_scores',\n",
        "          'detection_classes', 'detection_masks'\n",
        "      ]:\n",
        "        tensor_name = key + ':0'\n",
        "        if tensor_name in all_tensor_names:\n",
        "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "              tensor_name)        \n",
        "      \n",
        "      if 'detection_masks' in tensor_dict:\n",
        "        print('Detection masks in dictionary...')\n",
        "        # The following processing is only for single image\n",
        "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
        "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
        "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
        "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
        "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
        "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "        detection_masks_reframed = tf.cast(\n",
        "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "        # Follow the convention by adding back the batch dimension\n",
        "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "            detection_masks_reframed, 0)\n",
        "      \n",
        "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "      # Run inference\n",
        "      output_dict = sess.run(tensor_dict,\n",
        "                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "      output_dict['num_detections'] = int(output_dict['num_detections'][0])      \n",
        "      output_dict['detection_classes'] = output_dict[\n",
        "          'detection_classes'][0].astype(np.uint8)\n",
        "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "\n",
        "      if 'detection_masks' in output_dict:\n",
        "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "  return output_dict\n",
        "\n",
        "def calc_box(box):\n",
        "  return int(IMAGE_SIZE[1]*box[0]),int(IMAGE_SIZE[0]*box[1]),int(IMAGE_SIZE[1]*box[2]),int(IMAGE_SIZE[0]*box[3])\n",
        "\n",
        "def process_frame_queue(bufferedFrames, bufferedFrameTimeStamps, bufferedDict_1, bufferedDict_2, previousEvent):\n",
        "  '''\n",
        "  Before writing frames to output, spin through buffer to see if there are any game events between the frames\n",
        "  With the last x frames in the buffer (unless very start of game), figure out where the ball is on the frame and then which player(s) are near it.\n",
        "  Then, look at ball movement for these things:\n",
        "    1.  Dribble - mostly vertical movement but some horiz if player is moving\n",
        "    2.  Pass - ball moves away from the player box and for each frame gets further away\n",
        "    3.  Shot - ball moves away from the player box and for each frame gets further away, but also going in the Y direction faster rate than X (higher slope) \n",
        "  '''\n",
        "  index = 0\n",
        "  for frame in bufferedFrames:\n",
        "    bball_index = 0\n",
        "    for bball_key in bufferedDict_2[index]['detection_classes']:\n",
        "      if bball_key == BASKETBALL_KEY and bufferedDict_2[index]['detection_scores'][bball_index] > MIN_SCORE_THRESHOLD_BBALL:\n",
        "        #print(\"bball key: \" + str(bball_key))\n",
        "        #print(\"bball score: \" + str(bufferedDict_2[index]['detection_scores'][bball_index]))\n",
        "        # spin through player objects in dict1\n",
        "        player_index = 0\n",
        "        for player_key in bufferedDict_1[index]['detection_classes']:\n",
        "          #print(\"Player Key: \" + str(player_key))\n",
        "          #print(\"Player score: \" + str(output_dict_1['detection_scores'][player_index]))\n",
        "          if player_key > PLAYER_KEY and bufferedDict_1[index]['detection_scores'][player_index] > MIN_SCORE_THRESHOLD_COCO:\n",
        "            # get current coordinates for basketball\n",
        "            #print(\"Bball coords: \" + str(bufferedDict_2[index]['detection_boxes'][bball_index]))\n",
        "            #print(\"Player coords: \" + str(bufferedDict_1[index]['detection_boxes'][player_index]))\n",
        "          \n",
        "            #[y-min, x-min, y-max, x-max]\n",
        "            player_box = tuple(bufferedDict_1[index]['detection_boxes'][player_index])\n",
        "            bball_box = tuple(bufferedDict_2[index]['detection_boxes'][bball_index])\n",
        "\n",
        "            #extend the box dimensions to relate to the frame size\n",
        "            player_box = calc_box(player_box)\n",
        "            bball_box = calc_box(bball_box)\n",
        "            \n",
        "            #is the ball within the vertical range?\n",
        "            vert = False\n",
        "            horiz = False\n",
        "            if bball_box[0] in range(player_box[0],player_box[2]) and bball_box[2] in range(player_box[0],player_box[2]):\n",
        "              #print('Ball is within the vertical box of the player...' + str(bufferedDict_2[index]['detection_scores'][bball_index]))\n",
        "              vert = True\n",
        "            if bball_box[1] in range(player_box[1],player_box[3]) and bball_box[3] in range(player_box[1],player_box[3]):\n",
        "              #print('Ball is within the horizontal box of the player...')\n",
        "              horiz = True\n",
        "\n",
        "            if vert and horiz:\n",
        "              #[y-min, x-min, y-max, x-max]\n",
        "              #print(\"Bball Box Expanded: \" + str(bball_box))\n",
        "              #print(\"Player Box Expanded: \" + str(player_box))\n",
        "              \n",
        "              #the below is just used for debugging - printing on video where audio would be inserted\n",
        "              draw = ImageDraw.Draw(Image.fromarray(np.uint8(frame)))\n",
        "              #insert audio to for possession, but also check to make sure it is a new \"event\"\n",
        "              if player_key == HOME_PLAYER_KEY and previousEvent != 'home_possession':\n",
        "                print(\"Insert Audio, new event, HOME PLAYER HAS BALL\")\n",
        "                write_commentary_audio(bufferedFrameTimeStamps[index],'home_posession')\n",
        "                previousEvent = 'home_possession'\n",
        "                #draw.text((100, 100),'Insert Audio...HOME PLAYER HAS BALL',font=ImageFont.load_default())\n",
        "                #cv2.imwrite('/home/image-home-' + str(index) + '.jpg',frame)\n",
        "              elif player_key == AWAY_PLAYER_KEY and previousEvent != 'away_possession':\n",
        "                print(\"Insert Audio, new event, AWAY PLAYER HAS BALL\")\n",
        "                write_commentary_audio(bufferedFrameTimeStamps[index],'away_posession')\n",
        "                previousEvent = 'away_possession'\n",
        "                #draw.text((100, 100),'Insert Audio...HOME PLAYER HAS BALL',font=ImageFont.load_default())\n",
        "                #cv2.imwrite('/home/image-away-' + str(index) + '.jpg',frame)\n",
        "              \n",
        "          player_index += 1\n",
        "      bball_index += 1\n",
        "    index += 1\n",
        "  return previousEvent\n",
        "\n",
        "def write_audio(frameTime,timePrevious,actionType):\n",
        "  # NEED TO FIGURE OUT HOW TO MAKE AUDIO FILE PLAY OVER AGAIN IF TIME OF FILE IS LESS THAN REQUIRED DURATION OR\n",
        "  # CONCATENTATE MULTIPLE VIA A LOOP\n",
        "\n",
        "  frameTime = frameTime/1000\n",
        "\n",
        "  print ('**********')\n",
        "  print('Entering the write_audio function...')\n",
        "  print('actionType: '+ str(actionType))\n",
        "  print('timePrevious: ' + str(timePrevious))\n",
        "  print('frameTime:  ' + str(frameTime))\n",
        "  #print('required catchupClip Duration:' + str((frameTime-timePrevious)))\n",
        "\n",
        "  compo = None\n",
        "  catchupClipTemp = None\n",
        "  catchupClip = None\n",
        "\n",
        "  #scenario 1 and scenario #4\n",
        "  if timePrevious == 0 and actionType == '':\n",
        "    print('Scenario 1 or 4')\n",
        "    catchupClipTemp = AudioFileClip('/content/drive/My Drive/OBJ_Detect_POC/crowd_sound.wav')\n",
        "    catchupClip = afx.audio_loop(catchupClipTemp,duration=(frameTime-timePrevious))\n",
        "    compo = concatenate_audioclips([catchupClip])\n",
        "    compo.write_audiofile('/content/drive/My Drive/OBJ_Detect_POC/finalclip.wav',fps=11025,progress_bar=False,verbose=False)\n",
        "    compo.close()\n",
        "    catchupClipTemp.close()\n",
        "    catchupClip.close()\n",
        "\n",
        "    timePrevious = frameTime\n",
        "    print('timePrevious: ' + str(timePrevious))\n",
        "\n",
        "  #scenario 2\n",
        "  elif actionType != '':\n",
        "    print('Scenario 2')\n",
        "    # first see if we need to do a catchup\n",
        "    if frameTime > timePrevious:\n",
        "      catchupClipTemp = AudioFileClip('/content/drive/My Drive/OBJ_Detect_POC/crowd_sound.wav')\n",
        "      catchupClip = afx.audio_loop(catchupClipTemp,duration=(frameTime-timePrevious))\n",
        "      compo = concatenate_audioclips([catchupClip])\n",
        "      compo.write_audiofile('/content/drive/My Drive/OBJ_Detect_POC/finalclip.wav',fps=11025,progress_bar=False,verbose=False)\n",
        "      compo.close()\n",
        "      catchupClipTemp.close()\n",
        "      catchupClip.close()\n",
        "    \n",
        "    # next add the action clip\n",
        "    actionClipFile = ''\n",
        "\n",
        "    if actionType == 'home_posession':\n",
        "      actionClipFile = '/content/drive/My Drive/OBJ_Detect_POC/home_has_ball.wav'\n",
        "    elif actionType == 'away_posession':\n",
        "      actionClipFile = '/content/drive/My Drive/OBJ_Detect_POC/away_has_ball.wav'\n",
        "\n",
        "    finalClip = AudioFileClip('/content/drive/My Drive/OBJ_Detect_POC/finalclip.wav')\n",
        "    actionClip = AudioFileClip(actionClipFile)\n",
        "\n",
        "    actionClipDuration = actionClip.duration\n",
        "    print('Action Clip Duration: ' + str(actionClipDuration))\n",
        "\n",
        "    compo = concatenate_audioclips([finalClip,actionClip])\n",
        "    compo.write_audiofile('/content/drive/My Drive/OBJ_Detect_POC/finalclip.wav',fps=11025,progress_bar=False,verbose=False)\n",
        "    compo.close()\n",
        "    actionClip.close()\n",
        "    finalClip.close()\n",
        "\n",
        "    timePrevious = frameTime + actionClipDuration\n",
        "\n",
        "    print('timePrevious: ' + str(timePrevious))\n",
        "\n",
        "  #scenario 3 (should never get to this function for this scenario)  \n",
        "  #.....#\n",
        "\n",
        "  print ('**********')\n",
        "\n",
        "  return timePrevious\n",
        "\n",
        "# this function does logic on what type of game action currently happening\n",
        "def write_commentary_audio(frameTime,actionType):\n",
        "\n",
        "  print('FrameTime = ' + str(frameTime) + ', actionType = ' + actionType)\n",
        "\n",
        "  actionClipFile=''\n",
        "  if actionType == 'home_posession':\n",
        "    actionClipFile = '/content/drive/My Drive/OBJ_Detect_POC/home_has_ball.wav'\n",
        "  elif actionType == 'away_posession':\n",
        "    actionClipFile = '/content/drive/My Drive/OBJ_Detect_POC/away_has_ball.wav'\n",
        "\n",
        "  ffmpeg_overlay(frameTime,actionClipFile)\n",
        "  \n",
        "  return None\n",
        "\n",
        "# this function does the FFMPEG work\n",
        "def ffmpeg_overlay(frameTime, actionClipFile):\n",
        "\n",
        "  # first see if the seed audio.wav file is present, if not, then this is the first iteration, create it\n",
        "  if os.path.exists('/content/drive/My Drive/OBJ_Detect_POC/input.wav') == False:\n",
        "    print('input.wav not found, creating seed clip...')\n",
        "    create_seed_clip(0.25)\n",
        "\n",
        "  #command = \"ffmpeg -y -i '/content/drive/My Drive/OBJ_Detect_POC/background.wav' -i '/content/drive/My Drive/OBJ_Detect_POC/input.wav' -i '{}' -filter_complex '[0]volume=0.005,aloop=-1[a];[2]adelay={}|{},volume=2.0[delayed];[a][1][delayed]amix=3' '/content/drive/My Drive/OBJ_Detect_POC/audio.wav'\".format(actionClipFile, int(frameTime),int(frameTime))\n",
        "  #command = \"ffmpeg -y -i '/content/drive/My Drive/OBJ_Detect_POC/input.wav' -i '{}' -filter_complex '[1]adelay={}|{},volume=2.0[delayed];[0][delayed]amix=2' '/content/drive/My Drive/OBJ_Detect_POC/audio.wav'\".format(actionClipFile, int(frameTime),int(frameTime))\n",
        "  command = \"ffmpeg -y -i '/content/drive/My Drive/OBJ_Detect_POC/input.wav' -i '{}' -filter_complex '[1]adelay={}|{}[delayed];[0][delayed]amix=2' '/content/drive/My Drive/OBJ_Detect_POC/audio.wav'\".format(actionClipFile, int(frameTime),int(frameTime))\n",
        "\n",
        "  print(command)\n",
        "  print(subprocess.call(command, shell=True))\n",
        "\n",
        "  # rename output file to input\n",
        "  os.rename('/content/drive/My Drive/OBJ_Detect_POC/audio.wav','/content/drive/My Drive/OBJ_Detect_POC/input.wav')\n",
        "\n",
        "  return None\n",
        "\n",
        "\n",
        "# This function just creates a small seed audio file for first iteration to get it \"primed with an input.wav\"\n",
        "def create_seed_clip(clipDuration):\n",
        "\n",
        "  print('Creating seed clip, duration: ' + str(clipDuration/1000))\n",
        "\n",
        "  backClipTemp = AudioFileClip('/content/drive/My Drive/OBJ_Detect_POC/crowd_sound.wav')\n",
        "  backgroundClip = afx.audio_loop(backClipTemp,duration=(clipDuration/1000))\n",
        "  backgroundClip.write_audiofile('/content/drive/My Drive/OBJ_Detect_POC/input.wav',fps=11025,progress_bar=False,verbose=False)\n",
        "\n",
        "  backClipTemp.close()\n",
        "  backgroundClip.close()\n",
        "\n",
        "  return None\n",
        "\n",
        "def add_audio_clips():\n",
        "\n",
        "  #ffmpeg -y -i a.mp4 -itsoffset 00:00:30 -i sng.m4a -map 0:0 -map 1:0 -c:v copy -preset ultrafast -async 1 out.mp4\n",
        "  #command = \"ffmpeg -i {video} -ac 1  -f flac -vn {output}\".format(video=video, output=output)\n",
        "\n",
        "  command = \"ffmpeg -y -i '/content/drive/My Drive/OBJ_Detect_POC/background.wav' -itsoffset 2.5 -i '/content/drive/My Drive/OBJ_Detect_POC/away_has_ball.wav' -c:v copy -async 1 '/content/drive/My Drive/OBJ_Detect_POC/out.wav'\"\n",
        "  subprocess.call(command,shell=True)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoAnh6UXhmqL",
        "colab_type": "text"
      },
      "source": [
        "##Validation with Video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq_ZoP3bhpxJ",
        "colab_type": "code",
        "outputId": "95d94c05-dc5f-4b72-ec76-56ce1310d915",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import cv2\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from utils import label_map_util\n",
        "from utils import visualization_utils as vis_util\n",
        "import time\n",
        "\n",
        "\n",
        "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
        "PATH_TO_INPUT_VIDEO = '/content/drive/My Drive/OBJ_Detect_POC/learning/45secgame.mp4'\n",
        "#PATH_TO_INPUT_VIDEO = '/content/drive/My Drive/OBJ_Detect_POC/learning/ridgeland_stirr.mp4'\n",
        "PATH_TO_OUTPUT_VIDEO = '/content/drive/My Drive/OBJ_Detect_POC/learning' + str(int(round(time.time() * 1000))) + '.avi'\n",
        "MIN_SCORE_THRESHOLD_COCO = 0.85\n",
        "MIN_SCORE_THRESHOLD_BBALL = 0.6\n",
        "\n",
        "#white range - home team\n",
        "lower_home = np.array([179,197,218])\n",
        "upper_home = np.array([255,255,255])\n",
        "\n",
        "#dark/black range - visitor team\n",
        "lower_visitor = np.array([0,0,0])\n",
        "upper_visitor = np.array([30,30,40])\n",
        "\n",
        "#court color range\n",
        "lower_court = np.array([128,128,128])\n",
        "higher_court = np.array([255,255,255])\n",
        "\n",
        "# Open video\n",
        "cap = cv2.VideoCapture(PATH_TO_INPUT_VIDEO)\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (int(cap.get(3)), int(cap.get(4)))\n",
        "print('Frame Size: '+ str(IMAGE_SIZE))\n",
        "print('# Frames: ' + str(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "print('Clip Duration: ' + str(cap.get(cv2.CAP_PROP_POS_MSEC)))\n",
        "\n",
        "writer = None\n",
        "output_dict_1 = None\n",
        "output_dict_2 = None\n",
        "counter = 0\n",
        "NUM_BUFFERED_FRAMES = 10\n",
        "bufferedFrames = []\n",
        "bufferedDict_1 = []\n",
        "bufferedDict_2 = []\n",
        "bufferedFrameTimeStamps = []\n",
        "BASKETBALL_KEY = 1\n",
        "PLAYER_KEY = 90 #greater than this value\n",
        "HOME_PLAYER_KEY = 91\n",
        "AWAY_PLAYER_KEY = 92\n",
        "MAX_FRAMES_TO_PROCESS=-1\n",
        "previousEvent = '' # this variable holds the last event (i.e. home, away posession, shot, etc.)\n",
        "\n",
        "# get coco detection graph\n",
        "detection_graph_coco = setup_coco_model()\n",
        "# get the bball detection graph\n",
        "detection_graph_bball = setup_bball_model()\n",
        "\n",
        "# get coco cat index\n",
        "coco_category_index = get_category_index(os.path.join('/content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/data/', 'mscoco_label_map.pbtxt'),90)\n",
        "# get bball cat index\n",
        "bball_category_index = get_category_index(os.path.join('/content/drive/My Drive/OBJ_Detect_POC/learning/annotations/', 'label_map.pbtxt'),4)\n",
        "\n",
        "while(cap.isOpened()):\n",
        "  ret, orig_frame = cap.read()\n",
        "\n",
        "  if ret==True:\n",
        "  \n",
        "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "    # image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    \n",
        "    #frame = np.array(orig_frame)\n",
        "\n",
        "    frame = cv2.cvtColor(orig_frame,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    if frame is None:\n",
        "      print(\"Frame from video is null.\")\n",
        "      break\n",
        "\n",
        "    # Actual detection for coco\n",
        "    if output_dict_1 is not None:\n",
        "      output_dict_1.clear()\n",
        "    output_dict_1 = run_inference_for_single_image(frame, detection_graph_coco)\n",
        "\n",
        "    coco_category_index[91] = {'id' : HOME_PLAYER_KEY, 'name' : 'Home Player'}\n",
        "    coco_category_index[92] = {'id' : AWAY_PLAYER_KEY, 'name' : 'Away Player'}\n",
        "\n",
        "    # mask away everything but floor\n",
        "    court_mask = cv2.inRange(orig_frame, lower_court, higher_court)\n",
        "    court_output = cv2.bitwise_and(orig_frame,orig_frame,mask=court_mask)\n",
        "\n",
        "    # need to figure out which team each PERSON identified via the object detecion is on\n",
        "    index = 0\n",
        "    #iterate through all PERSON boxes and decide if home or visitor, set class name to Home Player or Away Player\n",
        "    for key in output_dict_1['detection_classes']:\n",
        "      #filter out class key (only looking for PERSON)\n",
        "      if coco_category_index[key]['name'] == 'person':        \n",
        "        #filter out scores less than threshold\n",
        "        if output_dict_1['detection_scores'][index] > MIN_SCORE_THRESHOLD_COCO:\n",
        "          #figure out if home or away team player\n",
        "          #[y-min, x-min, y-max, x-max], [y:y+h,x:x+w]\n",
        "          box = tuple(output_dict_1['detection_boxes'][index].tolist())\n",
        "          player_img = frame[int(IMAGE_SIZE[1]*box[0]):int(IMAGE_SIZE[1]*box[2]),int(IMAGE_SIZE[0]*box[1]):int(IMAGE_SIZE[0]*box[3])]\n",
        "          player_img = cv2.cvtColor(player_img,cv2.COLOR_BGR2RGB)\n",
        "          \n",
        "          #cv2.imwrite('/home/image-' + str(index).zfill(2) + 'a.jpg',player_img)\n",
        "          player_hsv = cv2.cvtColor(player_img,cv2.COLOR_RGB2HSV)\n",
        "          #cv2.imwrite('/home/image-' + str(index).zfill(2) + 'b.jpg',player_hsv)\n",
        "\n",
        "          #can play with each of the below to see which works best\n",
        "          #im_bin_128 = (player_img > 128) * 255\n",
        "          #im_bin_64 = (player_img > 64) * 255\n",
        "          im_bin_192 = (player_img > 180) * 255\n",
        "\n",
        "          new_image = np.reshape(im_bin_192,(im_bin_192.size,))\n",
        "\n",
        "          blackCount = 0\n",
        "          whiteCount = 0\n",
        "          \n",
        "          for pixel in new_image:\n",
        "            #print(pixel)\n",
        "            if pixel > 128:\n",
        "              whiteCount += 1\n",
        "            else:\n",
        "              blackCount += 1\n",
        "    \n",
        "          if whiteCount > 0.05*blackCount:\n",
        "            output_dict_1['detection_classes'][index] = 91\n",
        "            coco_category_index[91] = {'id':HOME_PLAYER_KEY, 'name' : 'Home Player'}\n",
        "          else:\n",
        "            output_dict_1['detection_classes'][index] = 92\n",
        "            coco_category_index[92] = {'id':AWAY_PLAYER_KEY, 'name' : 'Away Player'}\n",
        "\n",
        "        #else:\n",
        "          #print(\"Skipping b/c not above threshold of\",str(MIN_SCORE_THRESHOLD_COCO))\n",
        "\n",
        "      index += 1  \n",
        "\n",
        "\n",
        "    # Visualization of the results of the person/player detection.\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      frame,\n",
        "      output_dict_1['detection_boxes'],\n",
        "      output_dict_1['detection_classes'],\n",
        "      output_dict_1['detection_scores'],\n",
        "      coco_category_index,\n",
        "      instance_masks=output_dict_1.get('detection_masks'),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=8,\n",
        "      min_score_thresh=MIN_SCORE_THRESHOLD_COCO,\n",
        "      max_boxes_to_draw=50)\n",
        "    \n",
        "    \n",
        "    # Actual detection for bball\n",
        "    if output_dict_2 is not None:\n",
        "      output_dict_2.clear()\n",
        "    output_dict_2 = run_inference_for_single_image(frame, detection_graph_bball)\n",
        "    # Visualization of the results of a detection for the bball info.\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      frame,\n",
        "      output_dict_2['detection_boxes'],\n",
        "      output_dict_2['detection_classes'],\n",
        "      output_dict_2['detection_scores'],\n",
        "      bball_category_index,\n",
        "      instance_masks=output_dict_2.get('detection_masks'),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=8,\n",
        "      min_score_thresh=MIN_SCORE_THRESHOLD_BBALL,\n",
        "      max_boxes_to_draw=50)\n",
        "\n",
        "    # add frame to buffered Frames and inference output dictionaries which will be processed for commentary before writing to video file\n",
        "    bufferedFrames.append(frame)\n",
        "    bufferedFrameTimeStamps.append(cap.get(cv2.CAP_PROP_POS_MSEC))\n",
        "    bufferedDict_1.append(output_dict_1.copy())\n",
        "    bufferedDict_2.append(output_dict_2.copy())\n",
        "\n",
        "    #print(bufferedDict_1[counter].keys())\n",
        "    #print(bufferedDict_2[counter].keys())\n",
        "\n",
        "    # run a routine to determine where the ball is and where it went and for each change, does the ball share a box with a player and which team\n",
        "    # inject audio commentary for when ball is in player's possession (\"Auburn has the ball.\")\n",
        "    \n",
        "    # Need to \"hold\" past x frames and future 10 frames in object arrays\n",
        "    # ***************************************************************\n",
        "    if len(bufferedFrames) > NUM_BUFFERED_FRAMES:\n",
        "      # do the complex stuff to determine where ball is, etc.\n",
        "      previousEvent = process_frame_queue(bufferedFrames, bufferedFrameTimeStamps, bufferedDict_1, bufferedDict_2,previousEvent)\n",
        "\n",
        "      # if commentary necessary, mash audio to frame\n",
        "      \n",
        "      # Now time to write the marked up image/frame to the video file\n",
        "      if writer is None:\n",
        "        # Define the codec and create VideoWriter object\n",
        "        fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "        writer = cv2.VideoWriter(PATH_TO_OUTPUT_VIDEO,fourcc, cap.get(cv2.CAP_PROP_FPS), IMAGE_SIZE, True)\n",
        "      \n",
        "      for f in bufferedFrames:\n",
        "        writer.write(cv2.cvtColor(f,cv2.COLOR_BGR2RGB))\n",
        "\n",
        "      bufferedFrames.clear()\n",
        "      bufferedFrameTimeStamps.clear()\n",
        "      bufferedDict_1.clear()\n",
        "      bufferedDict_2.clear()\n",
        "    # ***************************************************************\n",
        "\n",
        "    counter += 1\n",
        "\n",
        "    if counter % 50 ==0 or counter == 1:\n",
        "      print('Counter=' + str(counter))\n",
        "\n",
        "    if MAX_FRAMES_TO_PROCESS != -1 and counter > MAX_FRAMES_TO_PROCESS:\n",
        "      break\n",
        "\n",
        "    if (cv2.waitKey(1) & 0xFF == ord('q')):\n",
        "      break\n",
        "\n",
        "  else:\n",
        "    print('Nothing there in video file, returned false.')\n",
        "    break;\n",
        "\n",
        "# flush remaining frames before breaking\n",
        "previousEvent = process_frame_queue(bufferedFrames, bufferedFrameTimeStamps, bufferedDict_1, bufferedDict_2,previousEvent)\n",
        "\n",
        "print('Writing remaining queued frames to video file...')\n",
        "for f in bufferedFrames:\n",
        "  writer.write(cv2.cvtColor(f,cv2.COLOR_BGR2RGB))\n",
        "\n",
        "# Release everything if job is finished\n",
        "if cap is not None:\n",
        "  cap.release()\n",
        "if writer is not None:\n",
        "  writer.release()  \n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# clean up seed audio file\n",
        "#if os.path.exists('/content/drive/My Drive/OBJ_Detect_POC/audio.wav') == True:\n",
        "  #os.remove('/content/drive/My Drive/OBJ_Detect_POC/audio.wav')\n",
        "\n",
        "print('Counter=' + str(counter))\n",
        "print('Processing completed...')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frame Size: (1224, 720)\n",
            "# Frames: 3226.0\n",
            "Clip Duration: 0.0\n",
            "Counter=1\n",
            "Insert Audio, new event, AWAY PLAYER HAS BALL\n",
            "FrameTime = 350.0, actionType = away_posession\n",
            "input.wav not found, creating seed clip...\n",
            "Creating seed clip, duration: 0.00025\n",
            "ffmpeg -y -i '/content/drive/My Drive/OBJ_Detect_POC/input.wav' -i '/content/drive/My Drive/OBJ_Detect_POC/away_has_ball.wav' -filter_complex '[1]adelay=350|350[delayed];[0][delayed]amix=2' '/content/drive/My Drive/OBJ_Detect_POC/audio.wav'\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XOt9blpOKG2",
        "colab_type": "text"
      },
      "source": [
        "## Run FFMPEG to Add Audio to Video File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6ueqEz4T16Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ffmpeg -y -i a.mp4 -itsoffset 00:00:30 -i sng.m4a -map 0:0 -map 1:0 -c:v copy -preset ultrafast -async 1 out.mp4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr2nESZMOO2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ffmpeg -i '/content/drive/My Drive/OBJ_Detect_POC/background.wav' -i '/content/drive/My Drive/OBJ_Detect_POC/output.avi' -filter_complex \"[0]adelay=2500|2500[b]\" '/content/drive/My Drive/OBJ_Detect_POC/output_with_audio.avi'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtyDaarCDG_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "add_audio_clips()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WnuMTmrciG4",
        "colab_type": "code",
        "outputId": "b6bbf36f-3b53-47aa-8581-387db6d4f19f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "create_background_clip(500)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating background clip, duration: 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpE1haX_ul6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(10):\n",
        "  if i % 2:\n",
        "    write_commentary_audio(i*1000,'away_posession')\n",
        "  else:\n",
        "    write_commentary_audio(i*1500,'home_posession')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPb5A-PrdN8W",
        "colab_type": "text"
      },
      "source": [
        "ffmpeg -y -i a.mp4 -itsoffset 00:00:30 -i sng.m4a -map 0:0 -map 1:0 -c:v copy -preset ultrafast -async 1 out.mp4\n",
        "\n",
        "-filter_complex amix=inputs=2:duration=longest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlaajqTxbq2d",
        "colab_type": "code",
        "outputId": "db51a57c-cc16-407a-dc53-5ecfcfea654d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "ffmpeg -y -i '/content/drive/My Drive/OBJ_Detect_POC/input.wav' -i '/content/drive/My Drive/OBJ_Detect_POC/home_has_ball.wav' -filter_complex '[1]adelay=0|0,volume=2.0[delayed];[0][delayed]amix=2' '/content/drive/My Drive/OBJ_Detect_POC/audio.wav'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-989b501d70ff>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ffmpeg -y -i '/content/drive/My Drive/OBJ_Detect_POC/input.wav' -i '/content/drive/My Drive/OBJ_Detect_POC/home_has_ball.wav' -filter_complex '[1]adelay=0|0,volume=2.0[delayed];[0][delayed]amix=2' '/content/drive/My Drive/OBJ_Detect_POC/audio.wav'\u001b[0m\n\u001b[0m                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jSF1VyaAc-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ffmpeg -y -i '/content/drive/My Drive/OBJ_Detect_POC/audio2.wav' -i '/content/drive/My Drive/OBJ_Detect_POC/away_has_ball.wav' -filter_complex \"[1]adelay=1500|1500,volume=2.0[delayed];[0][delayed]amix=2\" '/content/drive/My Drive/OBJ_Detect_POC/audio.wav'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9frbYod_geE",
        "colab_type": "code",
        "outputId": "b5bb7ffc-ce26-4539-a9ab-031854144628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "!ffmpeg -i '/content/drive/My Drive/OBJ_Detect_POC/input-video.avi' -i '/content/drive/My Drive/OBJ_Detect_POC/input.wav' -c copy '/content/drive/My Drive/OBJ_Detect_POC/output.avi'"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ffmpeg version 3.4.6-0ubuntu0.18.04.1 Copyright (c) 2000-2019 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.3.0-16ubuntu3)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.18.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, avi, from '/content/drive/My Drive/OBJ_Detect_POC/input-video.avi':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.35.100\n",
            "  Duration: N/A, start: 0.000000, bitrate: N/A\n",
            "    Stream #0:0: Video: mjpeg (MJPG / 0x47504A4D), yuvj420p(pc, bt470bg/unknown/unknown), 1224x720, 60 fps, 60 tbr, 60 tbn, 60 tbc\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #1.0 : stereo\n",
            "\u001b[0mInput #1, wav, from '/content/drive/My Drive/OBJ_Detect_POC/input.wav':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "  Duration: 00:00:03.14, bitrate: 1411 kb/s\n",
            "    Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
            "File '/content/drive/My Drive/OBJ_Detect_POC/output.avi' already exists. Overwrite ? [y/N] y\n",
            "Output #0, avi, to '/content/drive/My Drive/OBJ_Detect_POC/output.avi':\n",
            "  Metadata:\n",
            "    ISFT            : Lavf57.83.100\n",
            "    Stream #0:0: Video: mjpeg (MJPG / 0x47504A4D), yuvj420p(pc, bt470bg/unknown/unknown), 1224x720, q=2-31, 60 fps, 60 tbr, 60 tbn, 60 tbc\n",
            "    Stream #0:1: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (copy)\n",
            "  Stream #1:0 -> #0:1 (copy)\n",
            "Press [q] to stop, [?] for help\n",
            "frame=  590 fps=0.0 q=-1.0 Lsize=   80946kB time=00:00:09.83 bitrate=67435.2kbits/s speed=18.4x    \n",
            "video:80379kB audio:540kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.033360%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bM5j7H_PRpI5",
        "colab_type": "text"
      },
      "source": [
        "##Validation with Video (OLD)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E-mJ0wJRq4U",
        "colab_type": "code",
        "outputId": "65560e23-e513-4b24-eb7b-3aba1ba3a7de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "%cd ~\n",
        "%cd /content\n",
        "%cd drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import cv2\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from utils import label_map_util\n",
        "from utils import visualization_utils as vis_util\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT = '/content/drive/My Drive/OBJ_Detect_POC/learning/fine_tuned_model' + '/frozen_inference_graph.pb'\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = os.path.join('/content/drive/My Drive/OBJ_Detect_POC/learning/annotations', 'label_map.pbtxt')\n",
        "NUM_CLASSES = 4\n",
        "\n",
        "#-------------FUNCTION BELOW-------------------#\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "#-------------FUNCTION BELOW-------------------#\n",
        "\n",
        "def run_inference_for_single_image(image, graph):\n",
        "  with graph.as_default():\n",
        "    with tf.Session() as sess:\n",
        "      # Get handles to input and output tensors\n",
        "      ops = tf.get_default_graph().get_operations()\n",
        "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "      tensor_dict = {}\n",
        "      for key in [\n",
        "          'num_detections', 'detection_boxes', 'detection_scores',\n",
        "          'detection_classes', 'detection_masks'\n",
        "      ]:\n",
        "        tensor_name = key + ':0'\n",
        "        if tensor_name in all_tensor_names:\n",
        "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "              tensor_name)\n",
        "      if 'detection_masks' in tensor_dict:\n",
        "        # The following processing is only for single image\n",
        "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
        "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
        "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
        "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
        "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
        "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "        detection_masks_reframed = tf.cast(\n",
        "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "        # Follow the convention by adding back the batch dimension\n",
        "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "            detection_masks_reframed, 0)\n",
        "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "      # Run inference\n",
        "      output_dict = sess.run(tensor_dict,\n",
        "                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
        "      output_dict['detection_classes'] = output_dict[\n",
        "          'detection_classes'][0].astype(np.uint8)\n",
        "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "\n",
        "      if 'detection_masks' in output_dict:\n",
        "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "  return output_dict\n",
        "\n",
        "#-------------MAIN METHOD BELOW-------------------#\n",
        "\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')\n",
        "       \n",
        "    \n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
        "PATH_TO_INPUT_VIDEO = '/content/drive/My Drive/GOAL/tf/content/input.mp4'\n",
        "PATH_TO_OUTPUT_VIDEO = '/content/drive/My Drive/GOAL/tf/content/output.avi'\n",
        "\n",
        "os.chdir(PATH_TO_INPUT_VIDEO )\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (cap.get(3), cap.get(4))\n",
        "\n",
        "# Open video\n",
        "cap = cv2.VideoCapture(PATH_TO_INPUT_VIDEO)\n",
        "\n",
        "writer = None\n",
        "counter = 0\n",
        "\n",
        "while(cap.isOpened()):\n",
        "  ret, orig_frame = cap.read()\n",
        "  \n",
        "  if ret==True:\n",
        "    image_width, image_height = orig_frame.size\n",
        "  \n",
        "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "    # image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    \n",
        "    # Actual detection.\n",
        "    output_dict = run_inference_for_single_image(orig_frame, detection_graph)\n",
        "    \n",
        "    #frame = np.array(orig_frame)\n",
        "\n",
        "    if frame is None:\n",
        "      print(\"Masked image is null.\")\n",
        "      break\n",
        "    \n",
        "    # Visualization of the results of a detection.\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      orig_frame,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks'),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=8)\n",
        "    \n",
        "    # Now time to write the marked up image/frame to the video file\n",
        "    if writer is None:\n",
        "      # Define the codec and create VideoWriter object\n",
        "      fourcc = cv2.VideoWriter_fourcc(*\"MPG4\")\n",
        "      writer = cv2.VideoWriter('/content/drive/My Drive/GOAL/tf/content/output.avi',fourcc, 50.0, (int(cap.get(3)),int(cap.get(4))),True)\n",
        "   \n",
        "    writer.write(orig_frame)\n",
        "\n",
        "    counter += 1\n",
        "\n",
        "    # print(image_width, image_height)\n",
        "  \n",
        "    # print((left, right, top, bottom))\n",
        "    # print(output_dict['detection_boxes'][0][3])\n",
        "    # print(output_dict['detection_boxes'][0][0] * IMAGE_SIZE[1])\n",
        "    # print()\n",
        "    # print('-----')\n",
        "    # print(output_dict['detection_classes']) # 1 = basketball, 2 = hoop\n",
        "    # print('-----')\n",
        "    # print(category_index)\n",
        "    # print('-----')\n",
        "    # print(output_dict.get('detection_masks'))\n",
        "\n",
        "  else\n",
        "    print('Nothing there in video file, returned false.')\n",
        "\n",
        "  print('Counter=' & counter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-620f993a4806>\"\u001b[0;36m, line \u001b[0;32m170\u001b[0m\n\u001b[0;31m    else\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQ25tCGrmITA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# What model to download.\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "# PATH_TO_CKPT = '/content/drive/My Drive/OBJ_Detect_POC/learning/fine_tuned_model' + '/frozen_inference_graph.pb'\n",
        "# PATH_TO_CKPT = '/content/drive/My Drive/OBJ_Detect_POC/learning/image_test/pretrained_model' + '/frozen_inference_graph.pb'\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "# PATH_TO_LABELS = os.path.join('/content/drive/My Drive/OBJ_Detect_POC/learning/annotations', 'label_map.pbtxt')\n",
        "# PATH_TO_LABELS = os.path.join('/content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/data/', 'mscoco_label_map.pbtxt')\n",
        "\n",
        "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
        "PATH_TO_TEST_IMAGES_DIR = '/content/drive/My Drive/OBJ_Detect_POC/learning/image_test/'\n",
        "TEST_IMAGE_PATHS = []\n",
        "os.chdir(PATH_TO_TEST_IMAGES_DIR)\n",
        "\n",
        "for file in glob.glob(\"*.jpg\"):\n",
        "  TEST_IMAGE_PATHS.append(file)\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "#IMAGE_SIZE = (18, 12)\n",
        "\n",
        "counter = 0\n",
        "\n",
        "for image_path in TEST_IMAGE_PATHS:\n",
        "\n",
        "  if counter > 3:\n",
        "   break\n",
        "  \n",
        "  image = Image.open(image_path)\n",
        "  # the array based representation of the image will be used later in order to prepare the\n",
        "  # result image with boxes and labels on it.\n",
        "  #image_np = load_image_into_numpy_array(image)\n",
        "  image_np = np.array(image)\n",
        "  # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "  image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "\n",
        "  # first do coco indentification\n",
        "  detection_graph = setup_coco_model()\n",
        "\n",
        "  # Actual detection for coco\n",
        "  output_dict_1 = run_inference_for_single_image(image_np, detection_graph)\n",
        "\n",
        "  # Visualization of the results of a detection.\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict_1['detection_boxes'],\n",
        "      output_dict_1['detection_classes'],\n",
        "      output_dict_1['detection_scores'],\n",
        "      get_category_index(os.path.join('/content/drive/My Drive/OBJ_Detect_POC/learning/models/research/object_detection/data/', 'mscoco_label_map.pbtxt'),90),\n",
        "      instance_masks=output_dict_1.get('detection_masks'),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=8)\n",
        "  \n",
        "  # second, do the do bball indentification\n",
        "  detection_graph = setup_bball_model()\n",
        "  \n",
        "  # Actual detection for bball\n",
        "  output_dict_2 = run_inference_for_single_image(image_np, detection_graph)\n",
        "\n",
        "  # Visualization of the results of a detection for the bball info.\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict_2['detection_boxes'],\n",
        "      output_dict_2['detection_classes'],\n",
        "      output_dict_2['detection_scores'],\n",
        "      get_category_index(os.path.join('/content/drive/My Drive/OBJ_Detect_POC/learning/annotations/', 'label_map.pbtxt'),4),\n",
        "      instance_masks=output_dict_2.get('detection_masks'),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=8)\n",
        "\n",
        "  # print('---- converted coords ----')\n",
        "  image_width, image_height = image.size\n",
        "  # print(image_width, image_height)\n",
        "  ''' (left, right, top, bottom) = (output_dict['detection_boxes'][0][1] * image_width, output_dict['detection_boxes'][0][3] * image_width,\n",
        "                                  output_dict['detection_boxes'][0][0] * image_height, output_dict['detection_boxes'][0][2] * image_height)\n",
        "  '''\n",
        "  # print((left, right, top, bottom))\n",
        "\n",
        "  print(image.size)\n",
        "  counter += 1\n",
        "\n",
        "  display(Image.fromarray(image_np))\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgwyAf0fmEZT",
        "colab_type": "text"
      },
      "source": [
        "##Validation with Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDpOIUPwzsGD",
        "colab_type": "text"
      },
      "source": [
        "# More Utilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlvBq4Gq16bV",
        "colab_type": "text"
      },
      "source": [
        "##### Write session to logs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7Qs0LlD1bUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_writer = tf.summary.FileWriter('/content/drive/My Drive/OBJ_Detect_POC/learning/logs', tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isK7Ojh4zG2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "logdir = '/content/drive/My Drive/OBJ_Detect_POC/learning/logs'\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "%load_ext tensorboard\n",
        "%cd /content/drive/My Drive/OBJ_Detect_POC/learning\n",
        "\n",
        "%tensorboard --logdir ./logs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDekSr_TzLhy",
        "colab_type": "text"
      },
      "source": [
        "## Print filenames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOM6H_Hltk8G",
        "colab_type": "code",
        "outputId": "ff5b5775-1e71-4653-e8fb-d2e009cf5966",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "PATH_TO_TEST_IMAGES_DIR = '/content/drive/My Drive/OBJ_Detect_POC/learning/images/'\n",
        "TEST_IMAGE_PATHS = []\n",
        "os.chdir(PATH_TO_TEST_IMAGES_DIR)\n",
        "\n",
        "for file in glob.glob(\"*.jpg\"):\n",
        "  print(file)\n",
        "  TEST_IMAGE_PATHS.append(file)\n",
        "\n",
        "# print(TEST_IMAGE_PATHS)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image-01.jpg\n",
            "image-12.jpg\n",
            "image-26.jpg\n",
            "image-39.jpg\n",
            "image-54.jpg\n",
            "image-61.jpg\n",
            "image-92.jpg\n",
            "image-119.jpg\n",
            "image-165.jpg\n",
            "image-181.jpg\n",
            "image-243.jpg\n",
            "image-352.jpg\n",
            "image-734.jpg\n",
            "image-782.jpg\n",
            "image-844.jpg\n",
            "image-924.jpg\n",
            "image-972.jpg\n",
            "image-1052.jpg\n",
            "image-1418.jpg\n",
            "image-1614.jpg\n",
            "image-1810.jpg\n",
            "image-2647.jpg\n",
            "image-2664.jpg\n",
            "image-2734.jpg\n",
            "image-2706.jpg\n",
            "image-2689.jpg\n",
            "image-2756.jpg\n",
            "image-2767.jpg\n",
            "image-2805.jpg\n",
            "image-2788.jpg\n",
            "image-2816.jpg\n",
            "image-2841.jpg\n",
            "image-2856.jpg\n",
            "image-2871.jpg\n",
            "image-2954.jpg\n",
            "image-2883.jpg\n",
            "image-2896.jpg\n",
            "image-2909.jpg\n",
            "image-2959.jpg\n",
            "image-2920.jpg\n",
            "image-2929.jpg\n",
            "image-2940.jpg\n",
            "image-2976.jpg\n",
            "image-2946.jpg\n",
            "image-2995.jpg\n",
            "image-3009.jpg\n",
            "image-3030.jpg\n",
            "image-3179.jpg\n",
            "2nd-game-image-01.jpg\n",
            "2nd-game-image-02.jpg\n",
            "2nd-game-image-04.jpg\n",
            "2nd-game-image-03.jpg\n",
            "2nd-game-image-06.jpg\n",
            "2nd-game-image-07.jpg\n",
            "2nd-game-image-05.jpg\n",
            "2nd-game-image-00.jpg\n",
            "2nd-game-image-09.jpg\n",
            "2nd-game-image-08.jpg\n",
            "2nd-game-image-10.jpg\n",
            "2nd-game-image-252.jpg\n",
            "2nd-game-image-254.jpg\n",
            "2nd-game-image-12.jpg\n",
            "2nd-game-image-11.jpg\n",
            "2nd-game-image-253.jpg\n",
            "2nd-game-image-255.jpg\n",
            "2nd-game-image-14.jpg\n",
            "2nd-game-image-250.jpg\n",
            "2nd-game-image-251.jpg\n",
            "2nd-game-image-13.jpg\n",
            "2nd-game-image-256.jpg\n",
            "2nd-game-image-257.jpg\n",
            "2nd-game-image-258.jpg\n",
            "2nd-game-image-259.jpg\n",
            "2nd-game-image-265.jpg\n",
            "2nd-game-image-266.jpg\n",
            "2nd-game-image-260.jpg\n",
            "2nd-game-image-261.jpg\n",
            "2nd-game-image-267.jpg\n",
            "2nd-game-image-262.jpg\n",
            "2nd-game-image-268.jpg\n",
            "2nd-game-image-270.jpg\n",
            "2nd-game-image-269.jpg\n",
            "2nd-game-image-263.jpg\n",
            "2nd-game-image-264.jpg\n",
            "2nd-game-image-271.jpg\n",
            "2nd-game-image-272.jpg\n",
            "2nd-game-image-274.jpg\n",
            "2nd-game-image-273.jpg\n",
            "2nd-game-image-275.jpg\n",
            "2nd-game-image-281.jpg\n",
            "2nd-game-image-277.jpg\n",
            "2nd-game-image-276.jpg\n",
            "2nd-game-image-279.jpg\n",
            "2nd-game-image-278.jpg\n",
            "2nd-game-image-284.jpg\n",
            "2nd-game-image-280.jpg\n",
            "2nd-game-image-282.jpg\n",
            "2nd-game-image-283.jpg\n",
            "2nd-game-image-286.jpg\n",
            "2nd-game-image-285.jpg\n",
            "2nd-game-image-287.jpg\n",
            "2nd-game-image-288.jpg\n",
            "2nd-game-image-289.jpg\n",
            "['image-01.jpg', 'image-12.jpg', 'image-26.jpg', 'image-39.jpg', 'image-54.jpg', 'image-61.jpg', 'image-92.jpg', 'image-119.jpg', 'image-165.jpg', 'image-181.jpg', 'image-243.jpg', 'image-352.jpg', 'image-734.jpg', 'image-782.jpg', 'image-844.jpg', 'image-924.jpg', 'image-972.jpg', 'image-1052.jpg', 'image-1418.jpg', 'image-1614.jpg', 'image-1810.jpg', 'image-2647.jpg', 'image-2664.jpg', 'image-2734.jpg', 'image-2706.jpg', 'image-2689.jpg', 'image-2756.jpg', 'image-2767.jpg', 'image-2805.jpg', 'image-2788.jpg', 'image-2816.jpg', 'image-2841.jpg', 'image-2856.jpg', 'image-2871.jpg', 'image-2954.jpg', 'image-2883.jpg', 'image-2896.jpg', 'image-2909.jpg', 'image-2959.jpg', 'image-2920.jpg', 'image-2929.jpg', 'image-2940.jpg', 'image-2976.jpg', 'image-2946.jpg', 'image-2995.jpg', 'image-3009.jpg', 'image-3030.jpg', 'image-3179.jpg', '2nd-game-image-01.jpg', '2nd-game-image-02.jpg', '2nd-game-image-04.jpg', '2nd-game-image-03.jpg', '2nd-game-image-06.jpg', '2nd-game-image-07.jpg', '2nd-game-image-05.jpg', '2nd-game-image-00.jpg', '2nd-game-image-09.jpg', '2nd-game-image-08.jpg', '2nd-game-image-10.jpg', '2nd-game-image-252.jpg', '2nd-game-image-254.jpg', '2nd-game-image-12.jpg', '2nd-game-image-11.jpg', '2nd-game-image-253.jpg', '2nd-game-image-255.jpg', '2nd-game-image-14.jpg', '2nd-game-image-250.jpg', '2nd-game-image-251.jpg', '2nd-game-image-13.jpg', '2nd-game-image-256.jpg', '2nd-game-image-257.jpg', '2nd-game-image-258.jpg', '2nd-game-image-259.jpg', '2nd-game-image-265.jpg', '2nd-game-image-266.jpg', '2nd-game-image-260.jpg', '2nd-game-image-261.jpg', '2nd-game-image-267.jpg', '2nd-game-image-262.jpg', '2nd-game-image-268.jpg', '2nd-game-image-270.jpg', '2nd-game-image-269.jpg', '2nd-game-image-263.jpg', '2nd-game-image-264.jpg', '2nd-game-image-271.jpg', '2nd-game-image-272.jpg', '2nd-game-image-274.jpg', '2nd-game-image-273.jpg', '2nd-game-image-275.jpg', '2nd-game-image-281.jpg', '2nd-game-image-277.jpg', '2nd-game-image-276.jpg', '2nd-game-image-279.jpg', '2nd-game-image-278.jpg', '2nd-game-image-284.jpg', '2nd-game-image-280.jpg', '2nd-game-image-282.jpg', '2nd-game-image-283.jpg', '2nd-game-image-286.jpg', '2nd-game-image-285.jpg', '2nd-game-image-287.jpg', '2nd-game-image-288.jpg', '2nd-game-image-289.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "216xJdcUaA0y",
        "colab_type": "text"
      },
      "source": [
        "Split Video into Image Frames Saved to Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Fnl6bZDaG6H",
        "colab_type": "code",
        "outputId": "14297a79-b49d-44ba-9478-5c6ed50a012a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "cap = cv2.VideoCapture('/content/drive/My Drive/OBJ_Detect_POC/learning/45secgame.mp4')\n",
        "\n",
        "print(cap.get(3))\n",
        "print(cap.get(4))\n",
        "\n",
        "counter = 0\n",
        "while(cap.isOpened()):\n",
        "    ret, orig_frame = cap.read()\n",
        "    if ret==True:\n",
        "\n",
        "        frame = np.array(orig_frame)\n",
        "\n",
        "        if frame is None:\n",
        "          print(\"Masked image is null.\")\n",
        "          break\n",
        "        else:\n",
        "          # the below code will write each frame to disk for debugging purposes, delayed a bit to get rid of the preamble\n",
        "          # if counter > 1000 & counter < 1500:\n",
        "          cv2.imwrite('/content/drive/My Drive/OBJ_Detect_POC/learning/images_temp/3rd-game-image-' + str(counter).zfill(2) + '.jpg',frame)\n",
        "          counter = counter + 1\n",
        "        \n",
        "        if (cv2.waitKey(1) & 0xFF == ord('q') | counter > 50):\n",
        "            break\n",
        "        \n",
        "    else:\n",
        "        print('Video read returned false.')\n",
        "        break\n",
        "    if counter > 50:\n",
        "      break;\n",
        "\n",
        "# Release everything if job is finished\n",
        "if cap is not None:\n",
        "  cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "print('Image Splitting is Completed. ' + str(counter) + ' images were created.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1224.0\n",
            "720.0\n",
            "Image Splitting is Completed. 51 images were created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKSo04qIgyhZ",
        "colab_type": "code",
        "outputId": "ccc90994-57b7-4152-fe5c-ed58f1fdbc25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy\n",
        "numpy.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.18.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vNqZaRsidr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install pycocotools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi5ylwCDjeNz",
        "colab_type": "code",
        "outputId": "f541ec1d-75f4-4ccd-8b9c-1671c36e2d7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "pip show tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 1.15.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /tensorflow-1.15.0/python3.6\n",
            "Requires: numpy, tensorboard, wheel, grpcio, wrapt, keras-applications, six, tensorflow-estimator, google-pasta, absl-py, protobuf, opt-einsum, astor, keras-preprocessing, gast, termcolor\n",
            "Required-by: stable-baselines, magenta, tensorflow-federated, fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zx1709uQu5pV",
        "colab_type": "code",
        "outputId": "9772c9d2-b35e-41e5-8626-19fc3a83ee65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "pip show numpy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: numpy\n",
            "Version: 1.18.2\n",
            "Summary: NumPy is the fundamental package for array computing with Python.\n",
            "Home-page: https://www.numpy.org\n",
            "Author: Travis E. Oliphant et al.\n",
            "Author-email: None\n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: \n",
            "Required-by: tflearn, tensorflow, tensorflow-probability, tensorboard, tensor2tensor, stable-baselines, pretty-midi, mir-eval, magenta, kfac, graph-nets, yellowbrick, xgboost, xarray, wordcloud, umap-learn, torchvision, torchtext, thinc, Theano, tensorflow-model-optimization, tensorflow-hub, tensorflow-federated, tensorflow-datasets, tables, statsmodels, spacy, sklearn-pandas, seaborn, scs, scipy, scikit-learn, resampy, PyWavelets, pystan, pysndfile, pymc3, pyemd, pyarrow, plotnine, patsy, pandas, osqp, opt-einsum, opencv-python, opencv-contrib-python, numexpr, numba, np-utils, nibabel, moviepy, mlxtend, mizani, missingno, matplotlib, matplotlib-venn, lucid, lightgbm, librosa, knnimpute, Keras, Keras-Preprocessing, Keras-Applications, kapre, jpeg4py, jaxlib, jax, imgaug, imbalanced-learn, imageio, hyperopt, h5py, gym, gensim, folium, fix-yahoo-finance, featuretools, fbprophet, fastdtw, fastai, fancyimpute, fa2, ecos, daft, cvxpy, cupy-cuda101, cufflinks, cmdstanpy, chainer, Bottleneck, bokeh, blis, autograd, atari-py, astropy, altair, albumentations\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eIY2x6d4Dgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install numpy==1.17.3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-fPTgMhq0DF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "function ClickConnect(){\n",
        "console.log(\"Working\"); \n",
        "document.querySelector(\"colab-toolbar-button#connect\").click() \n",
        "}\n",
        "setInterval(ClickConnect,60000)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}